import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
import seaborn as sns
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
# import shutil
from datetime import datetime
from collections import defaultdict

# é…ç½®å‚æ•°
class Config:
    # è®­ç»ƒå‚æ•°
    BATCH_SIZE = 64
    EPOCHS = 50
    LEARNING_RATE = 1e-4
    WEIGHT_DECAY = 1e-5
    DROPOUT = 0.3
    DEVICE = torch.device("cuda:7" if torch.cuda.is_available() else "cpu")
    
    # æ•°æ®å¤„ç†å‚æ•°
    DATA_PATH = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/Task2_69_classification/CNN/CNN_features_v2"
    DATA_PATH = '/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/Task2_69_classification/CNN/CNN_features_v4_2048'
    TEST_SIZE = 0.2
    RANDOM_STATE = 42
    MAX_SAMPLES_PER_CLASS = 200
    
    # è¯„ä¼°å‚æ•°
    EVAL_METRIC = "weighted"
    PLOT_CONFUSION_MATRIX = True
    
    # æ—¥å¿—å’Œä¿å­˜å‚æ•°
    LOG_DIR = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/Task2_69_classification/CNN/Tensor_logs_2048"
    TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
    BEST_MODEL_PATH = os.path.join(LOG_DIR, f"best_model_{TIMESTAMP}.pt")
    METRICS_CSV = os.path.join(LOG_DIR, f"training_metrics_{TIMESTAMP}.csv")
    CONFUSION_MATRIX_PATH = os.path.join(LOG_DIR, f"confusion_matrix_{TIMESTAMP}.png")

# åˆ›å»ºæ—¥å¿—ç›®å½•
os.makedirs(Config.LOG_DIR, exist_ok=True)

# å®šä¹‰æ¨¡å‹
class ImprovedCNN(nn.Module):
    def __init__(self, input_channels, num_classes, feat_h, feat_w):
        super().__init__()
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)  # Hâ†’H/2, Wâ†’W/2
        )
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)  # H/2â†’H/4, W/2â†’W/4
        )
        
        self.dropout = nn.Dropout(Config.DROPOUT)
        self.flatten_dim = 64 * (feat_h // 4) * (feat_w // 4)
        self.fc = nn.Linear(self.flatten_dim, 128)
        self.output_layer = nn.Linear(128, num_classes)
        self.num_classes = num_classes

    def forward(self, x):
        if x.dim() == 3:
            x = x.unsqueeze(1)  # ç¡®ä¿è¾“å…¥ä¸º4D (B, C, H, W)
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = x.view(x.size(0), self.flatten_dim)
        x = self.fc(x)
        x = self.dropout(x)
        x = self.output_layer(x)
        return x

# è‡ªå®šä¹‰æ•°æ®é›†
class MelSpectrogramDataset(Dataset):
    def __init__(self, features, labels):
        self.features = features
        self.labels = labels
        
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

# åŠ è½½æ•°æ®
def load_data(data_path):
    print(f"ğŸ“‚ å¼€å§‹åŠ è½½æ•°æ® from {data_path}")
    
    # è·å–æ‰€æœ‰ç±»åˆ«
    class_folders = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]
    num_classes = len(class_folders)
    print(f"âœ… å‘ç° {num_classes} ä¸ªç±»åˆ«")
    
    # æ ‡ç­¾ç¼–ç 
    label_encoder = LabelEncoder()
    label_encoder.fit(class_folders)
    
    # åŠ è½½æ‰€æœ‰æ•°æ®
    all_feats = []
    all_labels = []
    
    # å…ˆåŠ è½½ä¸€ä¸ªæ–‡ä»¶è·å–å°ºå¯¸
    sample_class = class_folders[0]
    sample_file = [f for f in os.listdir(os.path.join(data_path, sample_class)) if f.endswith(".pt")][0]
    sample_path = os.path.join(data_path, sample_class, sample_file)
    sample_mel = torch.load(sample_path)
    feat_h, feat_w = sample_mel.shape
    print(f"âœ… æ¢…å°”é¢‘è°±å›¾å°ºå¯¸: {feat_h}x{feat_w}")
    
    # åŠ è½½æ‰€æœ‰æ–‡ä»¶
    for class_name in tqdm(class_folders, desc="åŠ è½½æ•°æ®"):
        class_path = os.path.join(data_path, class_name)
        file_list = [f for f in os.listdir(class_path) if f.endswith(".pt")]
        
        for file_name in file_list:
            file_path = os.path.join(class_path, file_name)
            try:
                mel = torch.load(file_path)
                all_feats.append(mel.numpy())
                all_labels.append(class_name)
            except Exception as e:
                print(f"âš ï¸ åŠ è½½æ–‡ä»¶ {file_path} å¤±è´¥: {str(e)}")
    
    # è½¬æ¢æ ‡ç­¾ä¸ºæ•°å­—
    all_labels_encoded = label_encoder.transform(all_labels)
    all_feats_np = np.array(all_feats)
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {all_feats_np.shape[0]} ä¸ªæ ·æœ¬")
    return all_feats_np, all_labels_encoded, label_encoder, num_classes, feat_h, feat_w

# æ•°æ®é¢„å¤„ç†ï¼ˆåˆ’åˆ†+å½’ä¸€åŒ–+é‡é‡‡æ ·ï¼‰
def preprocess_data(all_feats, all_labels):
    print(f"\nğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
    # 1. åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†
    train_feat, test_feat, train_label, test_label = train_test_split(
        all_feats, all_labels, 
        test_size=Config.TEST_SIZE, 
        stratify=all_labels, 
        random_state=Config.RANDOM_STATE
    )
    
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼š")
    print(f" - è®­ç»ƒé›†ï¼š{train_feat.shape[0]} æ ·æœ¬")
    print(f" - æµ‹è¯•é›†ï¼š{test_feat.shape[0]} æ ·æœ¬")
    
    # 2. å½’ä¸€åŒ–ï¼ˆZ-Scoreï¼‰
    # å±•å¹³ç‰¹å¾ä»¥è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
    train_feat_flat = train_feat.reshape(train_feat.shape[0], -1)
    train_mean = np.mean(train_feat_flat, axis=0)
    train_std = np.std(train_feat_flat, axis=0)
    train_std = np.where(train_std < 1e-8, 1e-8, train_std)  # é¿å…é™¤é›¶
    
    # åº”ç”¨å½’ä¸€åŒ–
    train_feat_reshaped = train_feat.reshape(train_feat.shape[0], -1)
    train_feat_norm = (train_feat_reshaped - train_mean) / train_std
    train_feat_norm = train_feat_norm.reshape(train_feat.shape)
    
    test_feat_reshaped = test_feat.reshape(test_feat.shape[0], -1)
    test_feat_norm = (test_feat_reshaped - train_mean) / train_std
    test_feat_norm = test_feat_norm.reshape(test_feat.shape)
    
    print(f"âœ… å½’ä¸€åŒ–å®Œæˆï¼š")
    print(f" - è®­ç»ƒé›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{train_feat_norm.min():.4f}, {train_feat_norm.max():.4f}]")
    print(f" - æµ‹è¯•é›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{test_feat_norm.min():.4f}, {test_feat_norm.max():.4f}]")
    
    # 3. é‡é‡‡æ ·ï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·+å°‘æ•°ç±»é‡å¤é‡‡æ ·ï¼‰
    print(f"\nâš–ï¸ å¼€å§‹é‡é‡‡æ ·ï¼ˆæ¯ç±»é™åˆ¶æœ€å¤§{Config.MAX_SAMPLES_PER_CLASS}æ ·æœ¬ï¼‰...")
    print(f" - é‡é‡‡æ ·å‰åˆ†å¸ƒï¼š")
    unique_labels = np.unique(train_label)
    for label in unique_labels:
        print(f" * ç±»åˆ«{label}ï¼š{np.sum(train_label == label)} æ ·æœ¬")
    
    # æŒ‰ç±»åˆ«æ”¶é›†æ•°æ®
    class_data = defaultdict(list)
    for feat, label in zip(train_feat_norm, train_label):
        class_data[label].append(feat)
    
    # é‡é‡‡æ ·
    resampled_data = []
    resampled_labels = []
    
    for label in class_data:
        samples = np.array(class_data[label])
        n_samples = len(samples)
        
        if n_samples >= Config.MAX_SAMPLES_PER_CLASS:
            # å¤šæ•°ç±»ï¼šéšæœºä¸‹é‡‡æ ·
            selected_idx = np.random.choice(n_samples, Config.MAX_SAMPLES_PER_CLASS, replace=False)
            resampled = samples[selected_idx]
        else:
            # å°‘æ•°ç±»ï¼šé‡å¤é‡‡æ ·
            resampled = resample(
                samples,
                replace=True,  # å…è®¸é‡å¤é‡‡æ ·
                n_samples=Config.MAX_SAMPLES_PER_CLASS,
                random_state=Config.RANDOM_STATE
            )
        
        resampled_data.append(resampled)
        resampled_labels.append(np.full(len(resampled), label))
    
    # åˆå¹¶é‡é‡‡æ ·åçš„æ•°æ®
    resampled_data = np.concatenate(resampled_data, axis=0)
    resampled_labels = np.concatenate(resampled_labels, axis=0)
    
    # è¾“å‡ºé‡é‡‡æ ·ç»“æœ
    print(f" - é‡é‡‡æ ·ååˆ†å¸ƒï¼š")
    for label in np.unique(resampled_labels):
        print(f" * ç±»åˆ«{label}ï¼š{np.sum(resampled_labels == label)} æ ·æœ¬")
    print(f" - æ€»æ ·æœ¬æ•°ï¼š{resampled_data.shape[0]}")
    
    return (
        resampled_data, resampled_labels,
        test_feat_norm, test_label,
        train_mean, train_std
    )

# è®­ç»ƒå‡½æ•°
def train_model(model, train_loader, val_loader, criterion, optimizer, writer, num_classes):
    best_val_f1 = 0.0
    metrics_history = []
    
    # åˆå§‹åŒ–CSVæ–‡ä»¶
    if not os.path.exists(Config.METRICS_CSV):
        pd.DataFrame(columns=[
            'epoch', 'train_loss', 'train_acc', 'train_precision', 
            'train_recall', 'train_f1', 'val_loss', 'val_acc',
            'val_precision', 'val_recall', 'val_f1'
        ]).to_csv(Config.METRICS_CSV, index=False)
    
    for epoch in range(Config.EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_preds = []
        train_targets = []
        
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{Config.EPOCHS} - Training"):
            inputs, labels = batch
            inputs, labels = inputs.to(Config.DEVICE), labels.to(Config.DEVICE)
            
            optimizer.zero_grad()
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item() * inputs.size(0)
            
            _, preds = torch.max(outputs, 1)
            train_preds.extend(preds.cpu().numpy())
            train_targets.extend(labels.cpu().numpy())
        
        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_loss = train_loss / len(train_loader.dataset)
        train_acc = accuracy_score(train_targets, train_preds)
        train_precision = precision_score(
            train_targets, train_preds, 
            average=Config.EVAL_METRIC, 
            zero_division=0
        )
        train_recall = recall_score(
            train_targets, train_preds, 
            average=Config.EVAL_METRIC, 
            zero_division=0
        )
        train_f1 = f1_score(
            train_targets, train_preds, 
            average=Config.EVAL_METRIC, 
            zero_division=0
        )
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_preds = []
        val_targets = []
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1}/{Config.EPOCHS} - Validation"):
                inputs, labels = batch
                inputs, labels = inputs.to(Config.DEVICE), labels.to(Config.DEVICE)
                
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item() * inputs.size(0)
                
                _, preds = torch.max(outputs, 1)
                val_preds.extend(preds.cpu().numpy())
                val_targets.extend(labels.cpu().numpy())
        
        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        val_loss = val_loss / len(val_loader.dataset)
        val_acc = accuracy_score(val_targets, val_preds)
        val_precision = precision_score(
            val_targets, val_preds, 
            average=Config.EVAL_METRIC, 
            zero_division=0
        )
        val_recall = recall_score(
            val_targets, val_preds, 
            average=Config.EVAL_METRIC, 
            zero_division=0
        )
        val_f1 = f1_score(
            val_targets, val_preds, 
            average=Config.EVAL_METRIC, 
            zero_division=0
        )
        
        # æ‰“å° epoch ç»“æœ
        print(f"\nEpoch {epoch+1}/{Config.EPOCHS}")
        print(f"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1: {train_f1:.4f}")
        print(f"Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}")
        
        # è®°å½•åˆ°TensorBoard
        writer.add_scalar('Loss/Train', train_loss, epoch)
        writer.add_scalar('Loss/Validation', val_loss, epoch)
        writer.add_scalar('Accuracy/Train', train_acc, epoch)
        writer.add_scalar('Accuracy/Validation', val_acc, epoch)
        writer.add_scalar('Precision/Train', train_precision, epoch)
        writer.add_scalar('Precision/Validation', val_precision, epoch)
        writer.add_scalar('Recall/Train', train_recall, epoch)
        writer.add_scalar('Recall/Validation', val_recall, epoch)
        writer.add_scalar('F1/Train', train_f1, epoch)
        writer.add_scalar('F1/Validation', val_f1, epoch)
        
        # ä¿å­˜æŒ‡æ ‡åˆ°CSV
        metrics_df = pd.DataFrame([{
            'epoch': epoch+1,
            'train_loss': train_loss,
            'train_acc': train_acc,
            'train_precision': train_precision,
            'train_recall': train_recall,
            'train_f1': train_f1,
            'val_loss': val_loss,
            'val_acc': val_acc,
            'val_precision': val_precision,
            'val_recall': val_recall,
            'val_f1': val_f1
        }])
        metrics_df.to_csv(Config.METRICS_CSV, mode='a', header=False, index=False)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_f1': best_val_f1
            }, Config.BEST_MODEL_PATH)
            print(f"ğŸ“Œ ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {best_val_f1:.4f}) åˆ° {Config.BEST_MODEL_PATH}")
    
    return model, metrics_history

# æµ‹è¯•å‡½æ•°
def test_model(model, test_loader, label_encoder):
    print("\nğŸ“Š å¼€å§‹æµ‹è¯•æœ€ä½³æ¨¡å‹...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    checkpoint = torch.load(Config.BEST_MODEL_PATH)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(Config.DEVICE)
    model.eval()
    
    test_preds = []
    test_targets = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing"):
            inputs, labels = batch
            inputs, labels = inputs.to(Config.DEVICE), labels.to(Config.DEVICE)
            
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            
            test_preds.extend(preds.cpu().numpy())
            test_targets.extend(labels.cpu().numpy())
    
    # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
    test_acc = accuracy_score(test_targets, test_preds)
    test_precision = precision_score(
        test_targets, test_preds, 
        average=Config.EVAL_METRIC, 
        zero_division=0
    )
    test_recall = recall_score(
        test_targets, test_preds, 
        average=Config.EVAL_METRIC, 
        zero_division=0
    )
    test_f1 = f1_score(
        test_targets, test_preds, 
        average=Config.EVAL_METRIC, 
        zero_division=0
    )
    
    print(f"\næµ‹è¯•ç»“æœ:")
    print(f"Accuracy: {test_acc:.4f}")
    print(f"Precision: {test_precision:.4f}")
    print(f"Recall: {test_recall:.4f}")
    print(f"F1 Score: {test_f1:.4f}")
    
    # è®°å½•æµ‹è¯•æŒ‡æ ‡åˆ°TensorBoard
    writer = SummaryWriter(Config.LOG_DIR)
    writer.add_scalar('Test/Accuracy', test_acc, 0)
    writer.add_scalar('Test/Precision', test_precision, 0)
    writer.add_scalar('Test/Recall', test_recall, 0)
    writer.add_scalar('Test/F1', test_f1, 0)
    writer.close()
    
    # è¿½åŠ æµ‹è¯•æŒ‡æ ‡åˆ°CSV
    test_metrics_df = pd.DataFrame([{
        'epoch': 'test',
        'train_loss': None,
        'train_acc': None,
        'train_precision': None,
        'train_recall': None,
        'train_f1': None,
        'val_loss': None,
        'val_acc': test_acc,
        'val_precision': test_precision,
        'val_recall': test_recall,
        'val_f1': test_f1
    }])
    test_metrics_df.to_csv(Config.METRICS_CSV, mode='a', header=False, index=False)
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    if Config.PLOT_CONFUSION_MATRIX:
        cm = confusion_matrix(test_targets, test_preds)
        plt.figure(figsize=(15, 12))
        sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', 
                   xticklabels=label_encoder.classes_,
                   yticklabels=label_encoder.classes_)
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.title('Confusion Matrix')
        plt.tight_layout()
        plt.savefig(Config.CONFUSION_MATRIX_PATH)
        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ° {Config.CONFUSION_MATRIX_PATH}")
    
    return test_acc, test_precision, test_recall, test_f1

# ä¸»å‡½æ•°
def main():
    print("===== æ¢…å°”é¢‘è°±å›¾ç–¾ç—…åˆ†ç±»è®­ç»ƒ =====")
    print(f"ä½¿ç”¨è®¾å¤‡: {Config.DEVICE}")
    
    # 1. åŠ è½½æ•°æ®
    all_feats, all_labels, label_encoder, num_classes, feat_h, feat_w = load_data(Config.DATA_PATH)
    
    # 2. æ•°æ®é¢„å¤„ç†
    train_feat, train_label, test_feat, test_label, train_mean, train_std = preprocess_data(all_feats, all_labels)
    
    # 3. åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = MelSpectrogramDataset(train_feat, train_label)
    test_dataset = MelSpectrogramDataset(test_feat, test_label)
    
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4)
    
    # 4. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    model = ImprovedCNN(
        input_channels=1,
        num_classes=num_classes,
        feat_h=feat_h,
        feat_w=feat_w
    ).to(Config.DEVICE)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(
        model.parameters(),
        lr=Config.LEARNING_RATE,
        weight_decay=Config.WEIGHT_DECAY
    )
    
    # 5. åˆå§‹åŒ–TensorBoard
    writer = SummaryWriter(Config.LOG_DIR)
    print(f"ğŸ“ TensorBoardæ—¥å¿—å°†ä¿å­˜åˆ°: {Config.LOG_DIR}")
    
    # 6. è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    model, _ = train_model(model, train_loader, test_loader, criterion, optimizer, writer, num_classes)
    writer.close()
    
    # 7. æµ‹è¯•æ¨¡å‹
    test_model(model, test_loader, label_encoder)
    
    print("\nğŸ‰ è®­ç»ƒå’Œæµ‹è¯•å®Œæˆ!")
    print(f"æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {Config.LOG_DIR}")

if __name__ == "__main__":
    main()
