import os
import sys
import random
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from pathlib import Path
import warnings
warnings.filterwarnings("ignore")

from torch.nn import DataParallel
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
from tqdm import tqdm


# å¼•å…¥é€šç”¨å·¥å…·ç»„ä»¶
sys.path.append(str(Path(__file__).parent.parent / "tools"))

from trainer.train_and_evaluate_time_moe_v2 import train_and_evaluate_time_moe  # è®­ç»ƒè¯„ä¼°æ¥å£
from utils.save_time_moe_results import save_time_moe_results  # ç»“æœä¿å­˜æ¥å£
from utils.metrics import calculate_class_distribution  # ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
from models.moe_model import TimeMoEClassifier  # Time-MoEåˆ†ç±»æ¨¡å‹
# from datasets.BaseDataset import BaseDataset
from models.BaseTimeDataset import BaseTimeDataset  # æ—¶åºæ•°æ®åŸºç±»ï¼ˆå·²å®ç°éŸ³é¢‘åŠ è½½/çª—å£é€»è¾‘ï¼‰



# ========================= æ ¸å¿ƒï¼šé…ç½®ç±»ï¼ˆå·²é€‚é…å¸•é‡‘æ£®ç—…æ•°æ®é›†ï¼‰=========================
class Config:
    """
    å¸•é‡‘æ£®ç—…æ•°æ®é›†é…ç½®ï¼šæŒ‰æ–‡ä»¶å¤¹åŒºåˆ†ç±»åˆ«ï¼ˆå¥åº·ç±»ï¼šM_Con/F_Conï¼›ç–¾ç—…ç±»ï¼šF_Dys/M_Dysï¼‰
    """
    # -------------------------- 1. æ•°æ®ç›¸å…³ï¼ˆå¸•é‡‘æ£®æ•°æ®é›†æ ¸å¿ƒé…ç½®ï¼‰--------------------------
    DATASET_NAME = "Parkinson_3700"  # æ•°æ®é›†åç§°ï¼ˆç”¨äºç»“æœä¿å­˜è·¯å¾„ï¼‰
    ROOT_DIR = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/dataset/Parkinson_3700"  # æ•°æ®é›†æ ¹ç›®å½•
    TRAIN_LABEL_PATH = None  # æ— CSVæ ‡ç­¾ï¼ŒæŒ‰æ–‡ä»¶å¤¹åŒºåˆ†ç±»åˆ«
    TEST_LABEL_PATH = None   
    CLASS_NAMES = ["Healthy", "Parkinson"]  # ç±»åˆ«æ˜ å°„ï¼š0=å¥åº·ï¼Œ1=å¸•é‡‘æ£®
    
    # éŸ³é¢‘ä¸æ—¶åºçª—å£é…ç½®ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰
    SAMPLE_RATE = 8000  # ç»Ÿä¸€é‡‡æ ·ç‡ï¼ˆä¸Time-MoEé¢„è®­ç»ƒåŒ¹é…ï¼‰
    WINDOW_SIZE = 2048   # æ—¶åºçª—å£å¤§å°ï¼ˆ4096é‡‡æ ·ç‚¹=0.256ç§’ï¼‰
    WINDOW_STRIDE = 2048 # çª—å£æ­¥é•¿ï¼ˆ2048é‡‡æ ·ç‚¹=0.128ç§’ï¼Œ50%é‡å ï¼‰
    AUDIO_EXT = ".wav"   # éŸ³é¢‘æ ¼å¼ï¼ˆå¸•é‡‘æ£®æ•°æ®é›†ä¸ºwavï¼‰

    # -------------------------- 2. æ¨¡å‹ç›¸å…³ï¼ˆä¿æŒä¸å˜ï¼‰--------------------------
    BACKBONE_PATH = "/mnt/data/test1/repo/Time-MoE/pretrain_model"  # Time-MoEé¢„è®­ç»ƒæƒé‡è·¯å¾„
    NUM_CLASSES = len(CLASS_NAMES)  # è‡ªåŠ¨æ¨å¯¼ç±»åˆ«æ•°ï¼ˆ2ç±»ï¼‰
    FREEZE_BACKBONE = True  # å†»ç»“éª¨å¹²ç½‘ç»œï¼Œä»…è®­ç»ƒåˆ†ç±»å¤´ï¼ˆèŠ‚çœç®—åŠ›ï¼‰
    DROPOUT_RATE = 0.1      # åˆ†ç±»å¤´dropouté˜²æ­¢è¿‡æ‹Ÿåˆ

    # -------------------------- 3. è®­ç»ƒç›¸å…³ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰--------------------------
    os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3,4"  
    DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"  # è®¾å¤‡é…ç½®
    SEED = 42  # éšæœºç§å­ï¼ˆä¿è¯å®éªŒå¯å¤ç°ï¼‰
    BATCH_SIZE = 8  # è®­ç»ƒæ‰¹å¤§å°ï¼ˆæ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ï¼Œå¦‚16/32ï¼‰
    NUM_EPOCHS = 10  # è®­ç»ƒè½®æ¬¡ï¼ˆå¸•é‡‘æ£®æ•°æ®é‡å¯èƒ½æ›´å¤§ï¼Œå»ºè®®10-20è½®ï¼‰
    LR = 1e-3  # åˆ†ç±»å¤´å­¦ä¹ ç‡ï¼ˆå†»ç»“éª¨å¹²æ—¶ç”¨1e-3ï¼Œè§£å†»æ—¶ç”¨1e-5ï¼‰
    WEIGHT_DECAY = 1e-4  # æƒé‡è¡°å‡ï¼ˆæ­£åˆ™åŒ–ï¼‰
    NUM_WORKERS = 16  # DataLoaderå·¥ä½œè¿›ç¨‹æ•°ï¼ˆåŒ¹é…CPUæ ¸å¿ƒæ•°ï¼‰

    # æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹ï¼ˆåˆ†å±‚åˆ’åˆ†ï¼Œä¿è¯å¥åº·/ç–¾ç—…ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼‰
    TRAIN_RATIO = 0.7
    VALID_RATIO = 0.15
    TEST_RATIO = 0.15

    MONO = True  # è½¬ä¸ºå•å£°é“
    NORMALIZE_AUDIO = True  # éŸ³é¢‘æ ‡å‡†åŒ–
    MIN_AUDIO_LENGTH = 10000  # éŸ³é¢‘æœ€å°é•¿åº¦ï¼ˆé‡‡æ ·ç‚¹ï¼Œâ‰ˆ0.0625ç§’@16kHzï¼‰
    SILENCE_THRESHOLD = 0.1  # é™éŸ³é˜ˆå€¼ï¼ˆæ ‡å‡†åŒ–åä¿¡å·çš„ç»å¯¹å€¼ï¼‰
    MAX_SILENCE_RATIO = 0.8  # æœ€å¤§é™éŸ³å æ¯”ï¼ˆè¶…è¿‡åˆ™è¿‡æ»¤ï¼‰

    # -------------------------- 4. è¾“å‡ºç›¸å…³ï¼ˆè‡ªåŠ¨ç”Ÿæˆè·¯å¾„ï¼‰--------------------------
    OUTPUT_DIR = os.path.join(Path(__file__).parent, "results", DATASET_NAME)  # ç»“æœä¿å­˜æ ¹è·¯å¾„
    os.makedirs(OUTPUT_DIR, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆä¸å­˜åœ¨æ—¶ï¼‰
    METRICS_FILENAME = f"{DATASET_NAME}_time_moe_metrics.txt"  # è¯¦ç»†æŒ‡æ ‡æ–‡ä»¶
    CONFUSION_MATRIX_FILENAME = f"{DATASET_NAME}_time_moe_cm.png"  # æ··æ·†çŸ©é˜µå›¾ç‰‡


# ========================= æ—¶åºæ•°æ®é›†ç±»ï¼ˆé€‚é…å¸•é‡‘æ£®å¤šæ–‡ä»¶å¤¹åˆ†ç±»ï¼‰=========================
# åµŒå…¥ä¸»å‡½æ•°æ‰€åœ¨æ–‡ä»¶ï¼ˆå¦‚ time_moe_doubao_v2.pyï¼‰ï¼Œä¸ BaseTimeDataset é…åˆä½¿ç”¨
class TimeMoEDataset(BaseTimeDataset):
    """
    å¸•é‡‘æ£®æ•°æ®é›†ä¸“å±å­ç±»ï¼ˆé€‚é… BaseTimeDataset çš„è¿‡æ»¤é€»è¾‘ï¼‰
    æ ¸å¿ƒåŠŸèƒ½ï¼šä»ConfigåŠ è½½æ•°æ®ã€è§£æå¸•é‡‘æ£®æ ‡ç­¾ï¼ˆæ–‡ä»¶å¤¹æ˜ å°„ï¼‰ã€ç”Ÿæˆæ¨¡å‹è¾“å…¥
    """
    
    def __init__(self, file_list, labels, config, mode="train"):
        """
        åˆå§‹åŒ–ï¼šè°ƒç”¨åŸºç±»æ„é€ å‡½æ•°ï¼Œä¼ é€’Configä¸­çš„è¿‡æ»¤å‚æ•°
        file_list: æœ‰æ•ˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æ— æ•ˆæ–‡ä»¶ï¼‰
        labels: å¯¹åº”éŸ³é¢‘çš„æ•´æ•°æ ‡ç­¾ï¼ˆ0=Healthyï¼Œ1=Parkinsonï¼‰
        config: ä¸»å‡½æ•°çš„Configå®ä¾‹ï¼ˆå«æ‰€æœ‰å‚æ•°ï¼‰
        mode: æ•°æ®é›†æ¨¡å¼ï¼ˆtrain/val/testï¼‰
        """
        # 1. è°ƒç”¨ BaseTimeDataset åŸºç±»åˆå§‹åŒ–ï¼ˆä¼ é€’è¿‡æ»¤å‚æ•°ï¼‰
        super().__init__(
            sample_rate=config.SAMPLE_RATE,
            mono=config.MONO,
            normalize=config.NORMALIZE_AUDIO,
            min_audio_length=config.MIN_AUDIO_LENGTH,
            silence_threshold=config.SILENCE_THRESHOLD,
            max_silence_ratio=config.MAX_SILENCE_RATIO
        )
        # 2. åˆå§‹åŒ–æ•°æ®é›†ç‰¹æœ‰å±æ€§
        self.config = config
        self.mode = mode  # æ§åˆ¶çª—å£æå–é€»è¾‘ï¼ˆtrain=éšæœºçª—ï¼Œval/test=æ»‘çª—ï¼‰
        self.file_list = file_list  # æœ‰æ•ˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        self.labels = labels        # æ•´æ•°æ ‡ç­¾åˆ—è¡¨
    
    @classmethod
    def from_config(cls, config, mode="train"):
        """
        ä»ConfigåŠ è½½æ•°æ®é›†ï¼ˆæ ¸å¿ƒæ¥å£ï¼Œä¸»å‡½æ•°è°ƒç”¨æ­¤æ–¹æ³•ï¼‰
        æµç¨‹ï¼šè·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ â†’ è¿‡æ»¤æ— æ•ˆæ–‡ä»¶ â†’ è§£ææ ‡ç­¾ â†’ è¿”å›æ•°æ®é›†å®ä¾‹
        """
        # æ­¥éª¤1ï¼šè·å–æ•°æ®é›†æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        all_audio_files = cls._get_all_audio_files(
            root_dir=config.ROOT_DIR,
            audio_ext=config.AUDIO_EXT
        )
        if not all_audio_files:
            raise ValueError(f"åœ¨æ•°æ®é›†æ ¹ç›®å½• {config.ROOT_DIR} ä¸­æœªæ‰¾åˆ° {config.AUDIO_EXT} æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶")
        print(f"\nğŸ” åŠ è½½ {mode} é›†åŸå§‹éŸ³é¢‘æ–‡ä»¶ï¼šå…± {len(all_audio_files)} ä¸ª")
        
        # æ­¥éª¤2ï¼šè¿‡æ»¤æ— æ•ˆæ–‡ä»¶ï¼ˆè°ƒç”¨åŸºç±» _load_audio åšæ–‡ä»¶çº§è¿‡æ»¤ï¼‰
        valid_files, valid_labels = cls._filter_invalid_files(
            all_audio_files=all_audio_files,
            config=config
        )
        if not valid_files:
            raise ValueError(f"{mode} é›†è¿‡æ»¤åæ— æœ‰æ•ˆéŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†æˆ–è°ƒæ•´è¿‡æ»¤å‚æ•°ï¼ˆå¦‚ min_audio_lengthã€max_silence_ratioï¼‰")
        print(f"âœ… {mode} é›†æ— æ•ˆæ–‡ä»¶è¿‡æ»¤å®Œæˆï¼š{len(all_audio_files)} ä¸ªåŸå§‹æ–‡ä»¶ â†’ {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
        
        # æ­¥éª¤3ï¼šè¿”å›æ•°æ®é›†å®ä¾‹
        return cls(
            file_list=valid_files,
            labels=valid_labels,
            config=config,
            mode=mode
        )
    
    @staticmethod
    def _get_all_audio_files(root_dir, audio_ext):
        """éå†æ ¹ç›®å½•ï¼Œè·å–æ‰€æœ‰æŒ‡å®šæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„"""
        audio_files = []
        # éå†æ ¹ç›®å½•åŠå…¶æ‰€æœ‰å­æ–‡ä»¶å¤¹
        for dir_path, _, file_names in os.walk(root_dir):
            for file_name in file_names:
                # ä»…ä¿ç•™æŒ‡å®šåç¼€çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                if file_name.lower().endswith(audio_ext.lower()):
                    audio_files.append(os.path.join(dir_path, file_name))
        return audio_files
    
    @classmethod
    def _filter_invalid_files(cls, all_audio_files, config):
        """è¿‡æ»¤æ— æ•ˆæ–‡ä»¶ï¼Œå¹¶åŒæ­¥è§£ææœ‰æ•ˆæ–‡ä»¶çš„æ ‡ç­¾"""
        valid_files = []
        valid_labels = []
        # åˆå§‹åŒ–åŸºç±»å®ä¾‹ï¼ˆä»…ç”¨äºè°ƒç”¨ _load_audio æ–¹æ³•ï¼Œæ— éœ€å®Œæ•´æ•°æ®é›†å±æ€§ï¼‰
        base_dataset = BaseTimeDataset(
            sample_rate=config.SAMPLE_RATE,
            mono=config.MONO,
            normalize=config.NORMALIZE_AUDIO,
            min_audio_length=config.MIN_AUDIO_LENGTH,
            silence_threshold=config.SILENCE_THRESHOLD,
            max_silence_ratio=config.MAX_SILENCE_RATIO
        )
        
        # éå†æ‰€æœ‰æ–‡ä»¶ï¼Œè¿‡æ»¤æ— æ•ˆæ–‡ä»¶å¹¶è§£ææ ‡ç­¾
        for file_path in all_audio_files:
            # è°ƒç”¨åŸºç±» _load_audio æ£€æŸ¥æ–‡ä»¶æœ‰æ•ˆæ€§
            wav, _ = base_dataset._load_audio(file_path, check_validity=True)
            if wav is not None:  # ä»…ä¿ç•™æœ‰æ•ˆæ–‡ä»¶
                valid_files.append(file_path)
                # è§£æå½“å‰æ–‡ä»¶çš„æ ‡ç­¾ï¼ˆå¸•é‡‘æ£®æ•°æ®é›†ï¼šæŒ‰æ–‡ä»¶å¤¹æ˜ å°„ï¼‰
                label = cls._parse_single_label(file_path, config.CLASS_NAMES)
                valid_labels.append(label)
        
        return valid_files, valid_labels
    
    @staticmethod
    def _parse_single_label(file_path, class_names):
        """
        å¸•é‡‘æ£®æ•°æ®é›†æ ‡ç­¾è§£æï¼ˆæ ¸å¿ƒæ˜ å°„é€»è¾‘ï¼‰
        æ–‡ä»¶å¤¹æ˜ å°„ï¼šM_Con/F_Con â†’ Healthyï¼ˆclass_names[0]ï¼Œæ ‡ç­¾0ï¼‰ï¼›F_Dys/M_Dys â†’ Parkinsonï¼ˆclass_names[1]ï¼Œæ ‡ç­¾1ï¼‰
        """
        # å®šä¹‰æ–‡ä»¶å¤¹ä¸ç±»åˆ«çš„æ˜ å°„ï¼ˆå¸•é‡‘æ£®æ•°æ®é›†ä¸“å±ï¼‰
        folder_label_map = {
            "M_Con": 0,  # ç”·æ€§å¥åº· â†’ æ ‡ç­¾0
            "F_Con": 0,  # å¥³æ€§å¥åº· â†’ æ ‡ç­¾0
            "F_Dys": 1,  # å¥³æ€§å¸•é‡‘æ£® â†’ æ ‡ç­¾1
            "M_Dys": 1   # ç”·æ€§å¸•é‡‘æ£® â†’ æ ‡ç­¾1
        }
        # æå–æ–‡ä»¶æ‰€åœ¨çš„çˆ¶æ–‡ä»¶å¤¹åç§°ï¼ˆå…³é”®ï¼šåŒºåˆ†ç±»åˆ«ï¼‰
        parent_folder = os.path.basename(os.path.dirname(file_path))
        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦åœ¨æ˜ å°„è¡¨ä¸­ï¼ˆé¿å…æœªçŸ¥æ–‡ä»¶å¤¹å¯¼è‡´é”™è¯¯ï¼‰
        if parent_folder not in folder_label_map:
            raise ValueError(f"æœªçŸ¥æ–‡ä»¶å¤¹ {parent_folder}ï¼Œè¯·æ›´æ–° folder_label_map æ˜ å°„è¡¨ï¼Œå½“å‰æ–‡ä»¶è·¯å¾„ï¼š{file_path}")
        return folder_label_map[parent_folder]
    
    def __getitem__(self, idx):
        """
        åŠ è½½å•ä¸ªæ ·æœ¬ï¼ˆä¸»å‡½æ•°DataLoaderè°ƒç”¨ï¼‰
        è¿”å›ï¼š
        - trainæ¨¡å¼ï¼š(éšæœºçª—å£, æ ‡ç­¾) â†’ [window_size], [1]
        - val/testæ¨¡å¼ï¼š(æœ‰æ•ˆæ»‘çª—, æ ‡ç­¾, æ–‡ä»¶è·¯å¾„) â†’ [num_valid_windows, window_size], [1], str
        """
        # 1. è·å–å½“å‰æ ·æœ¬çš„æ–‡ä»¶è·¯å¾„å’Œæ ‡ç­¾
        file_path = self.file_list[idx]
        label = self.labels[idx]
        
        # 2. åŠ è½½éŸ³é¢‘ï¼ˆè°ƒç”¨åŸºç±» _load_audioï¼Œå…³é—­check_validityï¼šå·²è¿‡æ»¤è¿‡ï¼‰
        wav, _ = self._load_audio(file_path, check_validity=False)
        
        # 3. æ ¹æ®æ¨¡å¼æå–çª—å£
        if self.mode == "train":
            # è®­ç»ƒæ¨¡å¼ï¼šéšæœºæå–1ä¸ªæœ‰æ•ˆçª—å£
            window = self._get_random_window(wav, window_size=self.config.WINDOW_SIZE)
            # æ ‡ç­¾è½¬ä¸ºLongTensorï¼ˆé€‚é…CrossEntropyLossï¼‰
            label_tensor = torch.tensor(label, dtype=torch.int64)
            return window, label_tensor
        
        else:
            # éªŒè¯/æµ‹è¯•æ¨¡å¼ï¼šæå–æ‰€æœ‰æœ‰æ•ˆæ»‘çª—
            windows = self._get_sliding_windows(
                wav=wav,
                window_size=self.config.WINDOW_SIZE,
                stride=self.config.WINDOW_STRIDE
            )
            # æ ‡ç­¾è½¬ä¸ºLongTensorï¼Œè¿”å›æ–‡ä»¶è·¯å¾„ç”¨äºæ»‘çª—ç»“æœèšåˆ
            label_tensor = torch.tensor(label, dtype=torch.int64)
            return windows, label_tensor, file_path
    
    def __len__(self):
        """è¿”å›æ•°æ®é›†æ ·æœ¬æ€»æ•°ï¼ˆæœ‰æ•ˆéŸ³é¢‘æ–‡ä»¶æ•°ï¼‰"""
        return len(self.file_list)


# ========================= ä¸»æµç¨‹ï¼ˆæ— éœ€ä¿®æ”¹ï¼Œç›´æ¥å¤ç”¨ï¼‰=========================
def main():
    # 1. åˆå§‹åŒ–é…ç½®ä¸å›ºå®šéšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°ï¼‰
    config = Config()
    torch.manual_seed(config.SEED)
    random.seed(config.SEED)
    np.random.seed(config.SEED)
    print(f"ğŸ“Œ å®éªŒé…ç½®ï¼šæ•°æ®é›†={config.DATASET_NAME} | ç±»åˆ«æ•°={config.NUM_CLASSES} | è®¾å¤‡={config.DEVICE}")
    print(f"ğŸ“Œ ç±»åˆ«æ˜ å°„ï¼š{dict(enumerate(config.CLASS_NAMES))}")

    # 2. åŠ è½½å®Œæ•´æ•°æ®é›†ï¼ˆè°ƒç”¨å¸•é‡‘æ£®ä¸“å±è§£æé€»è¾‘ï¼‰
    print("\n" + "="*80)
    print("1. åŠ è½½å¸•é‡‘æ£®ç—…æ•°æ®é›†")
    print("="*80)
    full_dataset = TimeMoEDataset.from_config(config, mode="train")  # åŠ è½½æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    print(f"âœ… å®Œæ•´æ•°æ®é›†è§„æ¨¡ï¼š{len(full_dataset)} ä¸ªéŸ³é¢‘æ–‡ä»¶")

    # 3. åˆ†å±‚åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆä¿è¯ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼‰
    print("\n" + "="*80)
    print("2. åˆ†å±‚åˆ’åˆ†æ•°æ®é›†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰")
    print("="*80)
    file_list = full_dataset.file_list
    labels = full_dataset.labels

    # ç¬¬ä¸€æ­¥ï¼šåˆ’åˆ†è®­ç»ƒé›† & ä¸´æ—¶é›†ï¼ˆå«éªŒè¯+æµ‹è¯•ï¼‰
    train_files, temp_files, train_labels, temp_labels = train_test_split(
        file_list, labels,
        test_size=config.VALID_RATIO + config.TEST_RATIO,
        stratify=labels,  # åˆ†å±‚åˆ’åˆ†æ ¸å¿ƒï¼šä¿è¯ç±»åˆ«æ¯”ä¾‹ä¸å˜
        random_state=config.SEED
    )

    # ç¬¬äºŒæ­¥ï¼šåˆ’åˆ†éªŒè¯é›† & æµ‹è¯•é›†
    val_files, test_files, val_labels, test_labels = train_test_split(
        temp_files, temp_labels,
        test_size=config.TEST_RATIO / (config.VALID_RATIO + config.TEST_RATIO),
        stratify=temp_labels,
        random_state=config.SEED
    )

    # æ„å»ºå„å­é›†æ•°æ®é›†
    train_dataset = TimeMoEDataset(train_files, train_labels, config, mode="train")
    val_dataset = TimeMoEDataset(val_files, val_labels, config, mode="val")
    test_dataset = TimeMoEDataset(test_files, test_labels, config, mode="test")

    # æ‰“å°ç±»åˆ«åˆ†å¸ƒï¼ˆéªŒè¯åˆ†å±‚åˆ’åˆ†æ•ˆæœï¼‰
    print("ğŸ“Š è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    train_dist = calculate_class_distribution(train_labels, config.CLASS_NAMES)
    for cls_name, (count, ratio) in train_dist.items():
        print(f"  {cls_name}: {count} ä¸ªï¼ˆ{ratio:.2f}%ï¼‰")
    
    print("ğŸ“Š éªŒè¯é›†ç±»åˆ«åˆ†å¸ƒï¼š")
    val_dist = calculate_class_distribution(val_labels, config.CLASS_NAMES)
    for cls_name, (count, ratio) in val_dist.items():
        print(f"  {cls_name}: {count} ä¸ªï¼ˆ{ratio:.2f}%ï¼‰")
    
    print("ğŸ“Š æµ‹è¯•é›†ç±»åˆ«åˆ†å¸ƒï¼š")
    test_dist = calculate_class_distribution(test_labels, config.CLASS_NAMES)
    for cls_name, (count, ratio) in test_dist.items():
        print(f"  {cls_name}: {count} ä¸ªï¼ˆ{ratio:.2f}%ï¼‰")

    # 4. æ„å»ºDataLoaderï¼ˆé€‚é…æ—¶åºçª—å£æ¨¡å¼ï¼‰
    print("\n" + "="*80)
    print("3. æ„å»ºDataLoader")
    print("="*80)
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=True,  # è®­ç»ƒé›†æ‰“ä¹±
        num_workers=config.NUM_WORKERS,
        pin_memory=True  # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=1,  # éªŒè¯é›†æŒ‰æ–‡ä»¶åŠ è½½ï¼ˆ1ä¸ªæ–‡ä»¶/æ‰¹ï¼‰
        shuffle=False,
        num_workers=config.NUM_WORKERS,
        pin_memory=True
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=1,  # æµ‹è¯•é›†æŒ‰æ–‡ä»¶åŠ è½½
        shuffle=False,
        num_workers=config.NUM_WORKERS,
        pin_memory=True
    )
    print(f"âœ… è®­ç»ƒLoaderï¼š{len(train_loader)} æ‰¹ï¼ˆæ‰¹å¤§å°{config.BATCH_SIZE}ï¼‰")
    print(f"âœ… éªŒè¯Loaderï¼š{len(val_loader)} ä¸ªæ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åŠ è½½ï¼‰")
    print(f"âœ… æµ‹è¯•Loaderï¼š{len(test_loader)} ä¸ªæ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åŠ è½½ï¼‰")
    print("\nã€éªŒè¯DataLoaderè¾“å‡ºç±»å‹ã€‘")
    train_iter = iter(train_loader)
    inputs, targets = next(train_iter)  # å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
    print(f"inputs dtype: {inputs.dtype}, targets dtype: {targets.dtype}")
    print(f"inputs shape: {inputs.shape}, targets shape: {targets.shape}")

    # 5. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    print("\n" + "="*80)
    print("4. åˆå§‹åŒ–æ¨¡å‹ä¸è®­ç»ƒç»„ä»¶")
    print("="*80)
    # model = TimeMoEClassifier(config)  # åˆå§‹åŒ–Time-MoEåˆ†ç±»æ¨¡å‹
    model = TimeMoEClassifier(config).to(config.DEVICE)
    model = DataParallel(model, device_ids=[0,1,2,3])  
    print(f"âœ… æ¨¡å‹ç»“æ„ï¼šTime-MoEéª¨å¹²ï¼ˆå†»ç»“ï¼‰ + åˆ†ç±»å¤´ï¼ˆ{config.NUM_CLASSES}ï¼‰")

    # æŸå¤±å‡½æ•°ï¼šæ”¯æŒç±»åˆ«åŠ æƒï¼ˆè‹¥æ•°æ®ä¸å¹³è¡¡ï¼Œå¯ä»è®­ç»ƒé›†åˆ†å¸ƒè®¡ç®—æƒé‡ï¼‰
    # è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆè§£å†³æ•°æ®ä¸å¹³è¡¡ï¼Œå¯é€‰ï¼‰
    # class_counts = np.bincount(train_labels)
    # class_weights = len(train_labels) / (len(config.CLASS_NAMES) * class_counts)
    # criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, device=config.DEVICE))
    # print(f"âœ… æŸå¤±å‡½æ•°ï¼šCrossEntropyLossï¼ˆç±»åˆ«æƒé‡={class_weights.round(4)}ï¼‰")
    class_counts = np.bincount(train_labels)
    class_weights = len(train_labels) / (len(config.CLASS_NAMES) * class_counts)
    # å…³é”®ï¼šæ˜¾å¼æŒ‡å®šdtype=torch.float32ï¼Œä¸æ¨¡å‹è¾“å‡ºlogitsç±»å‹ä¸€è‡´
    criterion = nn.CrossEntropyLoss(
        weight=torch.tensor(class_weights, device=config.DEVICE, dtype=torch.float32)
    )

    # æ·»åŠ ç±»å‹éªŒè¯æ‰“å°ï¼ˆç¡®è®¤ä¿®æ”¹æ•ˆæœï¼‰
    if criterion.weight is not None:
        print(f"âœ… æŸå¤±å‡½æ•°æƒé‡ç±»å‹: {criterion.weight.dtype}ï¼ˆåº”æ˜¾ç¤ºtorch.float32ï¼‰")
    else:
        print("âœ… æŸå¤±å‡½æ•°æœªä½¿ç”¨æƒé‡")

    # ä¼˜åŒ–å™¨ï¼šä»…ä¼˜åŒ–åˆ†ç±»å¤´ï¼ˆå†»ç»“éª¨å¹²æ—¶ï¼‰
    # ä¼˜åŒ–å™¨ï¼šä»…ä¼˜åŒ–åˆ†ç±»å¤´ï¼ˆå¤šå¡ä¸‹éœ€é€šè¿‡model.moduleè®¿é—®åŸæ¨¡å‹ï¼‰
    optimizer = torch.optim.AdamW(
        model.module.classifier.parameters(),  # å…³é”®ï¼šåŠ .moduleè®¿é—®åŸæ¨¡å‹çš„classifier
        lr=config.LR,
        weight_decay=config.WEIGHT_DECAY
    )
    print(f"âœ… ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆLR={config.LR}ï¼Œæƒé‡è¡°å‡={config.WEIGHT_DECAY}ï¼‰")

    # 6. è®­ç»ƒä¸è¯„ä¼°ï¼ˆè°ƒç”¨é€šç”¨æ¥å£ï¼‰
    print("\n" + "="*80)
    print("5. å¼€å§‹è®­ç»ƒä¸è¯„ä¼°")
    print("="*80)
    results = train_and_evaluate_time_moe(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        test_loader=test_loader,
        criterion=criterion,
        optimizer=optimizer,
        config=config
    )

    # 7. ä¿å­˜ç»“æœï¼ˆå«æŒ‡æ ‡æ–‡ä»¶ã€æ··æ·†çŸ©é˜µã€è®­ç»ƒæ›²çº¿ï¼‰
    print("\n" + "="*80)
    print("6. ä¿å­˜å®éªŒç»“æœ")
    print("="*80)
    save_time_moe_results(
        results=results,
        config=config,
        aggregation_strategy="mean"  # æ»‘çª—èšåˆç­–ç•¥ï¼ˆå‡å€¼ï¼‰
    )
    print(f"âœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³ï¼š{config.OUTPUT_DIR}")

    # 8. æ‰“å°æœ€ç»ˆæµ‹è¯•é›†æŒ‡æ ‡ï¼ˆå…³é”®ç»“æœï¼‰
    print("\n" + "="*80)
    print("7. å¸•é‡‘æ£®ç—…æ•°æ®é›†æœ€ç»ˆæµ‹è¯•ç»“æœ")
    print("="*80)
    final_metrics = results["final_test_metrics"]
    key_metrics = ["accuracy", "f1_score", "auc", "sensitivity", "specificity"]
    for metric in key_metrics:
        if metric in final_metrics:
            print(f"{metric.upper()}: {final_metrics[metric]:.4f}")


if __name__ == "__main__":
    main()