# save as: train_time_moe_classifier.py
import os
import sys
import random
import torch
import torchaudio 
import torch.nn as nn
from pathlib import Path
from torch.utils.data import DataLoader, random_split
import numpy as np
from transformers import AutoModelForCausalLM

# å¼•å…¥æ–°å†™çš„ç»„ä»¶
sys.path.append(str(Path(__file__).parent.parent / "tools"))
from trainer.train_and_evaluate_windows import train_and_evaluate_windows
from utils.audio_dataset import AudioWindowDataset


# ========== æ–°å¢ï¼šæ•°æ®ç»Ÿè®¡è¾…åŠ©å‡½æ•° ==========
def count_class_distribution(dataset):
    """ç»Ÿè®¡æ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒï¼ˆè¿”å›ç±»åˆ«æ•°é‡å’Œå æ¯”ï¼‰"""
    labels = dataset.labels
    total = len(labels)
    class_0_count = labels.count(0)  # non-covid
    class_1_count = labels.count(1)  # covid
    class_0_ratio = (class_0_count / total) * 100 if total > 0 else 0.0
    class_1_ratio = (class_1_count / total) * 100 if total > 0 else 0.0
    return {
        "total": total,
        "class_0": {"count": class_0_count, "ratio": round(class_0_ratio, 2)},  # non-covid
        "class_1": {"count": class_1_count, "ratio": round(class_1_ratio, 2)}   # covid
    }


def print_sample_details(dataset, dataset_name, sample_num=3):
    """æ‰“å°æ•°æ®é›†çš„éƒ¨åˆ†æ ·æœ¬è¯¦æƒ…ï¼ˆè·¯å¾„ã€æ ‡ç­¾ã€éŸ³é¢‘é•¿åº¦ç­‰ï¼‰"""
    print(f"\n=== {dataset_name} æ ·æœ¬è¯¦æƒ…ï¼ˆå‰{sample_num}ä¸ªï¼‰===")
    for i in range(min(sample_num, len(dataset))):
        file_path = dataset.file_list[i]
        label = dataset.labels[i]
        label_name = "covid" if label == 1 else "non-covid"
        
        # åŠ è½½éŸ³é¢‘è·å–åŸå§‹é•¿åº¦ï¼ˆé‡‡æ ·ç‚¹ï¼‰
        wav, sr = torchaudio.load(file_path)
        raw_length = wav.shape[1]  # éŸ³é¢‘åŸå§‹æ—¶é—´æ­¥æ•°ï¼ˆé‡‡æ ·ç‚¹ï¼‰
        raw_duration = raw_length / sr  # éŸ³é¢‘åŸå§‹æ—¶é•¿ï¼ˆç§’ï¼‰
        
        # è®¡ç®—å¤„ç†åçš„çª—å£æƒ…å†µ
        if dataset.mode == "train":
            window_info = f"1ä¸ªéšæœºçª—å£ï¼ˆå¤§å°ï¼š{dataset.window_size}é‡‡æ ·ç‚¹ï¼‰"
        else:
            # è®¡ç®—æ»‘çª—æ•°é‡ï¼ˆä¸__getitem__é€»è¾‘ä¸€è‡´ï¼‰
            max_start = max(1, raw_length - dataset.window_size + 1)
            num_windows = len(range(0, max_start, dataset.window_stride))
            window_info = f"{num_windows}ä¸ªæ»‘çª—ï¼ˆå¤§å°ï¼š{dataset.window_size}é‡‡æ ·ç‚¹ï¼Œæ­¥é•¿ï¼š{dataset.window_stride}é‡‡æ ·ç‚¹ï¼‰"
        
        print(f"æ ·æœ¬{i+1}:")
        print(f"  è·¯å¾„ï¼š{file_path}")
        print(f"  æ ‡ç­¾ï¼š{label}ï¼ˆ{label_name}ï¼‰")
        print(f"  åŸå§‹å±æ€§ï¼šé‡‡æ ·ç‡{sr}Hzï¼Œé•¿åº¦{raw_length}é‡‡æ ·ç‚¹ï¼ˆ{round(raw_duration, 2)}ç§’ï¼‰")
        print(f"  å¤„ç†åï¼š{window_info}")
        print("-" * 80)


# ========== CONFIG ==========
ROOT_DIR = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/dataset/COVID_19_CNN/data"
BACKBONE_PATH = "/mnt/data/test1/repo/Time-MoE/pretrain_model"
DEVICE = "cuda:2" if torch.cuda.is_available() else "cpu"
if torch.cuda.is_available():
    print("âœ… ä½¿ç”¨GPUè®­ç»ƒï¼ˆè®¾å¤‡ï¼š{}ï¼‰".format(DEVICE))
else:
    print("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
SEED = 42

# æ•°æ®ä¸è®­ç»ƒé…ç½®
SAMPLE_RATE = 16000
WINDOW_SIZE = 4096  # çª—å£å¤§å°ï¼ˆé‡‡æ ·ç‚¹ï¼‰â†’ å¯¹åº”æ—¶é•¿ï¼š4096/16000=0.256ç§’
WINDOW_STRIDE = 2048  # çª—å£æ­¥é•¿ï¼ˆé‡‡æ ·ç‚¹ï¼‰â†’ å¯¹åº”æ—¶é•¿ï¼š2048/16000=0.128ç§’
BATCH_SIZE = 8
NUM_WORKERS = 16
NUM_EPOCHS = 5
LR_HEAD = 1e-3
NUM_CLASSES = 2

# æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
TRAIN_RATIO = 0.7
VALID_RATIO = 0.15
TEST_RATIO = 0.15

# å›ºå®šéšæœºç§å­
torch.manual_seed(SEED)
random.seed(SEED)
np.random.seed(SEED)


# ========== MODEL WRAPPER ==========
class TimeMoEClassifier(nn.Module):
    def __init__(self, backbone_path, num_classes=2, device="cuda"):
        super().__init__()
        self.backbone = AutoModelForCausalLM.from_pretrained(
            backbone_path,
            trust_remote_code=True,
        )
        # å†»ç»“ backbone
        for p in self.backbone.parameters():
            p.requires_grad = False

        hidden_dim = self.backbone.config.hidden_size
        self.hidden_dim = hidden_dim

        # åˆ†ç±»å¤´
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.classifier = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, num_classes)
        )
        self.device = device
        self.to(device)

    def forward(self, x):
        x = x.to(self.device)
        inputs = x.unsqueeze(-1)  # [B, T] â†’ [B, T, 1]
        outputs = self.backbone.model(input_ids=inputs, return_dict=True)
        last_hidden = outputs.last_hidden_state  # [B, T, H]
        h = last_hidden.transpose(1, 2)  # [B, H, T]
        pooled = self.pool(h).squeeze(-1)  # [B, H]
        logits = self.classifier(pooled)
        return logits, last_hidden


# ========== MAIN ==========
def main():
    # ========= 1. åŠ è½½å®Œæ•´æ•°æ®é›† & æ‰“å°æ•´ä½“ä¿¡æ¯ =========
    print("=" * 80)
    print("ğŸ“Š 1. æ•´ä½“æ•°æ®é›†ä¿¡æ¯")
    print("=" * 80)
    
    full_dataset = AudioWindowDataset.from_root_dir(
        ROOT_DIR,
        mode="train",  # æš‚ç”¨trainæ¨¡å¼åŠ è½½ï¼Œåç»­ä¼šé‡æ–°æŒ‡å®šå­é›†æ¨¡å¼
        sample_rate=SAMPLE_RATE,
        window_size=WINDOW_SIZE,
        window_stride=WINDOW_STRIDE,
    )
    
    # ç»Ÿè®¡æ•´ä½“ç±»åˆ«åˆ†å¸ƒ
    full_dist = count_class_distribution(full_dataset)
    print(f"æ•´ä½“æ•°æ®é›†æ€»éŸ³é¢‘æ–‡ä»¶æ•°ï¼š{full_dist['total']}")
    print(f"non-covidï¼ˆç±»åˆ«0ï¼‰ï¼š{full_dist['class_0']['count']}ä¸ªï¼ˆå æ¯”{full_dist['class_0']['ratio']}%ï¼‰")
    print(f"covidï¼ˆç±»åˆ«1ï¼‰ï¼š{full_dist['class_1']['count']}ä¸ªï¼ˆå æ¯”{full_dist['class_1']['ratio']}%ï¼‰")
    
    # æ‰“å°æ•´ä½“æ•°æ®é›†çš„éƒ¨åˆ†æ ·æœ¬è¯¦æƒ…
    print_sample_details(full_dataset, "æ•´ä½“æ•°æ®é›†", sample_num=2)


    # ========= 2. æ•°æ®é›†ä¸‰åˆ’åˆ† & æ‰“å°å­é›†ä¿¡æ¯ï¼ˆä¿®æ”¹ä¸ºåˆ†å±‚åˆ’åˆ†ï¼‰ =========
    print("\n" + "=" * 80)
    print("ğŸ“Š 2. è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†ä¿¡æ¯ï¼ˆåˆ†å±‚åˆ’åˆ†ï¼‰")
    print("=" * 80)
    
    n_total = len(full_dataset)
    # ä»å®Œæ•´æ•°æ®é›†ä¸­æå–æ–‡ä»¶è·¯å¾„å’Œæ ‡ç­¾ï¼ˆç”¨äºåˆ†å±‚åˆ’åˆ†ï¼‰
    full_file_list = full_dataset.file_list
    full_labels = full_dataset.labels

    # --------------------------
    # ç¬¬ä¸€æ­¥ï¼šåˆ’åˆ†ã€Œè®­ç»ƒé›†ã€å’Œã€Œä¸´æ—¶é›†ã€ï¼ˆå«éªŒè¯+æµ‹è¯•ï¼‰
    # --------------------------
    from sklearn.model_selection import train_test_split  # å¯¼å…¥åˆ†å±‚åˆ’åˆ†å·¥å…·
    # stratify=full_labelsï¼šä¿è¯åˆ’åˆ†åè®­ç»ƒé›†å’Œä¸´æ—¶é›†çš„ç±»åˆ«æ¯”ä¾‹ä¸æ•´ä½“ä¸€è‡´
    train_file_list, temp_file_list, train_labels, temp_labels = train_test_split(
        full_file_list, full_labels,
        test_size=VALID_RATIO + TEST_RATIO,  # ä¸´æ—¶é›†å æ¯”ï¼š15%+15%=30%
        stratify=full_labels,
        random_state=SEED  # å›ºå®šç§å­ä¿è¯å¯å¤ç°
    )

    # --------------------------
    # ç¬¬äºŒæ­¥ï¼šåˆ’åˆ†ã€Œä¸´æ—¶é›†ã€ä¸ºã€ŒéªŒè¯é›†ã€å’Œã€Œæµ‹è¯•é›†ã€
    # --------------------------
    # stratify=temp_labelsï¼šä¿è¯éªŒè¯é›†å’Œæµ‹è¯•é›†çš„ç±»åˆ«æ¯”ä¾‹ä¸ä¸´æ—¶é›†ä¸€è‡´ï¼ˆé—´æ¥ä¸æ•´ä½“ä¸€è‡´ï¼‰
    val_file_list, test_file_list, val_labels, test_labels = train_test_split(
        temp_file_list, temp_labels,
        test_size=TEST_RATIO / (VALID_RATIO + TEST_RATIO),  # æµ‹è¯•é›†å ä¸´æ—¶é›†çš„50%ï¼ˆ15%/30%ï¼‰
        stratify=temp_labels,
        random_state=SEED
    )

    # --------------------------
    # æ„å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆä¸åŸä»£ç é€»è¾‘ä¸€è‡´ï¼Œä»…æ•°æ®æºä»ç´¢å¼•æ”¹ä¸ºç›´æ¥åˆ’åˆ†åçš„åˆ—è¡¨ï¼‰
    # --------------------------
    train_set = AudioWindowDataset(
        file_list=train_file_list,  # ç›´æ¥ç”¨åˆ†å±‚åˆ’åˆ†åçš„æ–‡ä»¶åˆ—è¡¨
        labels=train_labels,        # ç›´æ¥ç”¨åˆ†å±‚åˆ’åˆ†åçš„æ ‡ç­¾
        mode="train",
        sample_rate=SAMPLE_RATE,
        window_size=WINDOW_SIZE,
        window_stride=WINDOW_STRIDE,
    )
    val_set = AudioWindowDataset(
        file_list=val_file_list,
        labels=val_labels,
        mode="eval",
        sample_rate=SAMPLE_RATE,
        window_size=WINDOW_SIZE,
        window_stride=WINDOW_STRIDE,
        return_file_id=True,
    )
    test_set = AudioWindowDataset(
        file_list=test_file_list,
        labels=test_labels,
        mode="eval",
        sample_rate=SAMPLE_RATE,
        window_size=WINDOW_SIZE,
        window_stride=WINDOW_STRIDE,
        return_file_id=True,
    )


    # ç»Ÿè®¡å„å­é›†ç±»åˆ«åˆ†å¸ƒ
    train_dist = count_class_distribution(train_set)
    val_dist = count_class_distribution(val_set)
    test_dist = count_class_distribution(test_set)

    # æ‰“å°åˆ’åˆ†ç»“æœ
    print(f"\nåˆ’åˆ†æ¯”ä¾‹ï¼šè®­ç»ƒé›†{TRAIN_RATIO*100}% | éªŒè¯é›†{VALID_RATIO*100}% | æµ‹è¯•é›†{TEST_RATIO*100}%")
    print(f"\nè®­ç»ƒé›†ï¼š")
    print(f"  éŸ³é¢‘æ–‡ä»¶æ•°ï¼š{train_dist['total']}")
    print(f"  non-covidï¼š{train_dist['class_0']['count']}ä¸ªï¼ˆ{train_dist['class_0']['ratio']}%ï¼‰ | covidï¼š{train_dist['class_1']['count']}ä¸ªï¼ˆ{train_dist['class_1']['ratio']}%ï¼‰")
    print(f"  è®­ç»ƒæ—¶å®é™…æ ·æœ¬æ•°ï¼š{train_dist['total']}ï¼ˆæ¯ä¸ªæ–‡ä»¶1ä¸ªéšæœºçª—å£ï¼‰")

    print(f"\néªŒè¯é›†ï¼š")
    print(f"  éŸ³é¢‘æ–‡ä»¶æ•°ï¼š{val_dist['total']}")
    print(f"  non-covidï¼š{val_dist['class_0']['count']}ä¸ªï¼ˆ{val_dist['class_0']['ratio']}%ï¼‰ | covidï¼š{val_dist['class_1']['count']}ä¸ªï¼ˆ{val_dist['class_1']['ratio']}%ï¼‰")

    print(f"\næµ‹è¯•é›†ï¼š")
    print(f"  éŸ³é¢‘æ–‡ä»¶æ•°ï¼š{test_dist['total']}")
    print(f"  non-covidï¼š{test_dist['class_0']['count']}ä¸ªï¼ˆ{test_dist['class_0']['ratio']}%ï¼‰ | covidï¼š{test_dist['class_1']['count']}ä¸ªï¼ˆ{test_dist['class_1']['ratio']}%ï¼‰")

    # æ‰“å°å„å­é›†çš„æ ·æœ¬è¯¦æƒ…ï¼ˆéªŒè¯æ•°æ®å¤„ç†é€»è¾‘ï¼‰
    print_sample_details(train_set, "è®­ç»ƒé›†", sample_num=2)
    print_sample_details(val_set, "éªŒè¯é›†", sample_num=2)


    # ========= 3. æ„å»ºDataLoader & æ‰“å°åŠ è½½ä¿¡æ¯ =========
    print("\n" + "=" * 80)
    print("ğŸ“Š 3. DataLoaderé…ç½®ä¿¡æ¯")
    print("=" * 80)
    
    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)
    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)

    print(f"è®­ç»ƒé›†DataLoaderï¼šæ‰¹å¤§å°{BATCH_SIZE}ï¼Œ shuffle={True}ï¼Œ å·¥ä½œè¿›ç¨‹æ•°{NUM_WORKERS}")
    print(f"è®­ç»ƒé›†æ¯è½®è¿­ä»£æ¬¡æ•°ï¼š{len(train_loader)}ï¼ˆæ€»çª—å£æ•°{len(train_set)} / æ‰¹å¤§å°{BATCH_SIZE}ï¼‰")
    print(f"éªŒè¯é›†DataLoaderï¼šæ‰¹å¤§å°1ï¼ˆæŒ‰æ–‡ä»¶åŠ è½½ï¼‰ï¼Œ shuffle={False}")
    print(f"æµ‹è¯•é›†DataLoaderï¼šæ‰¹å¤§å°1ï¼ˆæŒ‰æ–‡ä»¶åŠ è½½ï¼‰ï¼Œ shuffle={False}")


    # ========= 4. æ¨¡å‹åˆå§‹åŒ– & è®­ç»ƒ =========
    print("\n" + "=" * 80)
    print("ğŸš€ 4. æ¨¡å‹åˆå§‹åŒ–ä¸è®­ç»ƒå¯åŠ¨")
    print("=" * 80)
    
    model = TimeMoEClassifier(BACKBONE_PATH, num_classes=NUM_CLASSES, device=DEVICE)
    print(f"Backboneæ¨¡å‹ï¼šTime-MoEï¼Œ éšè—å±‚ç»´åº¦ï¼š{model.hidden_dim}")
    print(f"åˆ†ç±»å¤´ï¼šLayerNorm â†’ Dropout(0.1) â†’ Linear({model.hidden_dim}â†’{NUM_CLASSES})")
    print(f"ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆä»…è®­ç»ƒåˆ†ç±»å¤´ï¼Œå­¦ä¹ ç‡{LR_HEAD}ï¼Œæƒé‡è¡°å‡1e-4ï¼‰")
    print(f"æŸå¤±å‡½æ•°ï¼šCrossEntropyLossï¼ˆæœªåŠ æƒï¼Œéœ€å…³æ³¨ç±»åˆ«å¹³è¡¡ï¼‰")
    print(f"è®­ç»ƒè½®æ¬¡ï¼š{NUM_EPOCHS}")

    optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=LR_HEAD, weight_decay=1e-4)
    criterion = nn.CrossEntropyLoss()

    # è®­ç»ƒ&è¯„ä¼°
    results = train_and_evaluate_windows(
        model,
        train_loader,
        val_loader,
        test_loader,
        criterion,
        optimizer,
        config=type("Config", (), {
            "NUM_EPOCHS": NUM_EPOCHS,
            "CLASS_NAMES": ["non_covid", "covid"]
        })()
    )

    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæµ‹è¯•é›†ç»“æœï¼š")
    print("=" * 80)
    for metric_name, value in results["final_test_metrics"].items():
        print(f"{metric_name}: {round(value, 2)}")


if __name__ == "__main__":
    main()