import os
import shutil
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing

class Config:
    # æºæ•°æ®é…ç½®ï¼ˆä¸åŸRAWDysPeechæ•°æ®é›†ç±»ä¿æŒä¸€è‡´ï¼‰
    SOURCE_ROOT = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/dataset/RAWDysPeech"
    CLASS_NAMES = ["Healthy", "Disease"]  # 0:å¥åº·, 1:ç–¾ç—…
    SOURCE_LABEL_DIRS = {
        0: os.path.join(SOURCE_ROOT, "0"),  # æºå¥åº·ç»„æ–‡ä»¶å¤¹ï¼ˆç›®å½•å"0"ï¼‰
        1: os.path.join(SOURCE_ROOT, "1")   # æºç–¾ç—…ç»„æ–‡ä»¶å¤¹ï¼ˆç›®å½•å"1"ï¼‰
    }
    
    # ç›®æ ‡ç›®å½•é…ç½®
    DESTINATION_ROOT = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/fresh_datasets/RAWDysPeech"
    TARGET_DIRS = {
        0: os.path.join(DESTINATION_ROOT, "Healthy"),  # ç›®æ ‡å¥åº·ç»„æ–‡ä»¶å¤¹
        1: os.path.join(DESTINATION_ROOT, "Disease")   # ç›®æ ‡ç–¾ç—…ç»„æ–‡ä»¶å¤¹
    }
    
    # å¤šçº¿ç¨‹é…ç½®ï¼ˆé€‚é…116æ ¸å¿ƒCPUï¼Œçº¿ç¨‹æ•°è®¾ä¸ºæ ¸å¿ƒæ•°çš„1.5å€ï¼Œå¹³è¡¡IOä¸CPUï¼‰
    MAX_WORKERS = min(int(multiprocessing.cpu_count() * 1.5), 128)  # ä¸Šé™128é¿å…çº¿ç¨‹è¿‡å¤šå¼€é”€

class RAWDysPeechProcessor:
    @staticmethod
    def create_target_directories():
        """åˆ›å»ºç›®æ ‡å¥åº·ç»„å’Œç–¾ç—…ç»„æ–‡ä»¶å¤¹ï¼Œæ£€æŸ¥æºæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨"""
        # æ£€æŸ¥æºæ–‡ä»¶å¤¹å®Œæ•´æ€§
        for label, source_dir in Config.SOURCE_LABEL_DIRS.items():
            if not os.path.exists(source_dir):
                raise ValueError(f"âŒ æºç±»åˆ«æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{source_dir}ï¼ˆæ ‡ç­¾ï¼š{label}ï¼Œå¯¹åº”ç±»åˆ«ï¼š{Config.CLASS_NAMES[label]}ï¼‰")
            print(f"âœ… æºç±»åˆ«æ–‡ä»¶å¤¹å­˜åœ¨ï¼š{source_dir}ï¼ˆ{Config.CLASS_NAMES[label]}ï¼‰")
        
        # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
        os.makedirs(Config.DESTINATION_ROOT, exist_ok=True)
        print(f"\nâœ… ç›®æ ‡æ ¹ç›®å½•å·²å‡†å¤‡ï¼š{Config.DESTINATION_ROOT}")
        
        for label, target_dir in Config.TARGET_DIRS.items():
            if os.path.exists(target_dir):
                print(f"âœ… ç›®æ ‡ç±»åˆ«æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼š{target_dir}ï¼ˆ{Config.CLASS_NAMES[label]}ï¼‰")
            else:
                os.makedirs(target_dir, exist_ok=True)
                print(f"âœ… æˆåŠŸåˆ›å»ºç›®æ ‡ç±»åˆ«æ–‡ä»¶å¤¹ï¼š{target_dir}ï¼ˆ{Config.CLASS_NAMES[label]}ï¼‰")
    
    @staticmethod
    def get_labeled_file_list():
        """æ”¶é›†æ‰€æœ‰å¸¦æ ‡ç­¾çš„WAVæ–‡ä»¶è·¯å¾„ï¼ˆä»æºç±»åˆ«æ–‡ä»¶å¤¹"0"/"1"ä¸­ç­›é€‰ï¼‰"""
        file_list = []
        
        for label, source_dir in Config.SOURCE_LABEL_DIRS.items():
            # ç­›é€‰å½“å‰æºæ–‡ä»¶å¤¹ä¸‹çš„WAVæ–‡ä»¶
            wav_files = [f for f in os.listdir(source_dir) if f.lower().endswith(".wav")]
            if not wav_files:
                raise ValueError(f"âŒ æºç±»åˆ«æ–‡ä»¶å¤¹{source_dir}ä¸­æœªæ‰¾åˆ°ä»»ä½•WAVæ–‡ä»¶ï¼ˆ{Config.CLASS_NAMES[label]}ï¼‰")
            
            # ç»„è£…æ–‡ä»¶è·¯å¾„ä¸æ ‡ç­¾ï¼ˆä»…ä¿ç•™å¿…è¦çš„ä¸‰å…ƒç»„ç»“æ„ï¼‰
            for filename in wav_files:
                file_path = os.path.join(source_dir, filename)
                file_list.append((file_path, label, filename))  # (æºè·¯å¾„, æ ‡ç­¾, æ–‡ä»¶å)
        
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        healthy_count = sum(1 for _, label, _ in file_list if label == 0)
        disease_count = sum(1 for _, label, _ in file_list if label == 1)
        
        print(f"\nâœ… æˆåŠŸæ”¶é›†åˆ° {len(file_list)} ä¸ªWAVæ–‡ä»¶")
        print(f"   - {Config.CLASS_NAMES[0]}ï¼ˆæºç›®å½•'0'ï¼‰ï¼š{healthy_count} ä¸ª")
        print(f"   - {Config.CLASS_NAMES[1]}ï¼ˆæºç›®å½•'1'ï¼‰ï¼š{disease_count} ä¸ª")
        
        if not file_list:
            raise ValueError("âŒ æœªæ”¶é›†åˆ°ä»»ä½•WAVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æºç›®å½•ç»“æ„å’Œæ–‡ä»¶æ ¼å¼")
        
        return file_list
    
    @staticmethod
    def calculate_file_hash(file_path, block_size=65536):
        """ä¿®å¤å“ˆå¸Œè®¡ç®—è¿”å›å€¼ï¼šç»Ÿä¸€è¿”å›(å“ˆå¸Œå€¼, é”™è¯¯ä¿¡æ¯)äºŒå…ƒç»„ï¼Œé¿å…è§£åŒ…å¼‚å¸¸"""
        hasher = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                buf = f.read(block_size)
                while buf:
                    hasher.update(buf)
                    buf = f.read(block_size)
            return (hasher.hexdigest(), "")  # æˆåŠŸï¼šè¿”å›å“ˆå¸Œå€¼+ç©ºé”™è¯¯ä¿¡æ¯
        except Exception as e:
            return (None, f"å“ˆå¸Œè®¡ç®—å¤±è´¥ï¼š{str(e)}")  # å¤±è´¥ï¼šè¿”å›None+é”™è¯¯ä¿¡æ¯
    
    @staticmethod
    def get_unique_filename(target_dir, original_filename):
        """ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆé‡å¤æ—¶æ·»åŠ æ•°å­—åç¼€ï¼Œå¦‚file_1.wavï¼‰"""
        base_name, ext = os.path.splitext(original_filename)
        counter = 1
        
        # æ£€æŸ¥åŸå§‹æ–‡ä»¶åæ˜¯å¦å¯ç”¨
        if not os.path.exists(os.path.join(target_dir, original_filename)):
            return original_filename
        
        # å¾ªç¯ç”Ÿæˆå¸¦åç¼€çš„æ–‡ä»¶åï¼Œç›´åˆ°æ‰¾åˆ°å¯ç”¨åç§°
        while True:
            new_filename = f"{base_name}_{counter}{ext}"
            new_path = os.path.join(target_dir, new_filename)
            if not os.path.exists(new_path):
                return new_filename
            counter += 1
    
    @staticmethod
    def copy_single_file(file_info):
        """å•æ–‡ä»¶å¤åˆ¶ä»»åŠ¡ï¼ˆä¿®å¤è¿”å›å€¼è§£åŒ…é—®é¢˜ï¼Œç¡®ä¿é€»è¾‘ç¨³å®šï¼‰"""
        source_path, label, filename = file_info  # ä»…è§£åŒ…ä¸‰å…ƒç»„ï¼ŒåŒ¹é…ä¼ å…¥çš„file_listç»“æ„
        target_dir = Config.TARGET_DIRS[label]
        target_cls_name = Config.CLASS_NAMES[label]
        dest_path = os.path.join(target_dir, filename)
        
        try:
            # æ­¥éª¤1ï¼šè®¡ç®—æºæ–‡ä»¶å“ˆå¸Œï¼ˆä¿®å¤åè¿”å›äºŒå…ƒç»„ï¼Œè§£åŒ…æ— å¼‚å¸¸ï¼‰
            source_hash, hash_err = RAWDysPeechProcessor.calculate_file_hash(source_path)
            if source_hash is None:
                return (
                    "fail", 
                    label, 
                    filename, 
                    f"æºæ–‡ä»¶{filename}å“ˆå¸Œè®¡ç®—å¤±è´¥ï¼š{hash_err}"
                )
            
            # æ­¥éª¤2ï¼šå¤„ç†æ–‡ä»¶åé‡å¤
            if os.path.exists(dest_path):
                # è®¡ç®—ç›®æ ‡æ–‡ä»¶å“ˆå¸Œï¼ˆåŒæ ·ä¿®å¤äº†è§£åŒ…é—®é¢˜ï¼‰
                target_hash, target_hash_err = RAWDysPeechProcessor.calculate_file_hash(dest_path)
                if target_hash is None:
                    return (
                        "fail", 
                        label, 
                        filename, 
                        f"ç›®æ ‡æ–‡ä»¶{filename}å“ˆå¸Œè®¡ç®—å¤±è´¥ï¼š{target_hash_err}"
                    )
                
                # å†…å®¹ç›¸åŒâ†’è·³è¿‡ï¼Œå†…å®¹ä¸åŒâ†’é‡å‘½å
                if source_hash == target_hash:
                    return ("skip_identical", label, filename, f"å†…å®¹å®Œå…¨ç›¸åŒï¼Œè·³è¿‡å¤åˆ¶")
                else:
                    new_filename = RAWDysPeechProcessor.get_unique_filename(target_dir, filename)
                    dest_path = os.path.join(target_dir, new_filename)
                    copy_msg = f"æ–‡ä»¶åé‡å¤ï¼Œé‡å‘½åä¸º{new_filename}åå¤åˆ¶"
            else:
                copy_msg = "ç›´æ¥å¤åˆ¶"
            
            # æ­¥éª¤3ï¼šæ‰§è¡Œå¤åˆ¶ï¼ˆä¿ç•™æ–‡ä»¶å…ƒæ•°æ®ï¼‰
            shutil.copy2(source_path, dest_path)
            return ("success", label, os.path.basename(dest_path), copy_msg)
        
        except Exception as e:
            return (
                "fail", 
                label, 
                filename, 
                f"å¤åˆ¶è¿‡ç¨‹å¼‚å¸¸ï¼š{str(e)[:60]}..."  # æˆªå–é”™è¯¯ä¿¡æ¯ï¼Œé¿å…è¿‡é•¿
            )
    
    @staticmethod
    def multi_thread_copy(file_list):
        """å¤šçº¿ç¨‹å¤åˆ¶æ–‡ä»¶ï¼šç¨³å®šå¤„ç†ä»»åŠ¡æäº¤ä¸ç»“æœè¿”å›"""
        # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
        stats = {
            "success": 0,
            "skip_identical": 0,
            "fail": 0,
            "class_count": {0: 0, 1: 0},  # æŒ‰æ ‡ç­¾ç»Ÿè®¡æˆåŠŸæ•°
            "fail_files": []  # è®°å½•å¤±è´¥æ–‡ä»¶ä¿¡æ¯
        }
        
        print(f"\n" + "="*60)
        print(f"å¼€å§‹å¤šçº¿ç¨‹å¤åˆ¶ï¼ˆçº¿ç¨‹æ•°ï¼š{Config.MAX_WORKERS}ï¼Œæ€»æ–‡ä»¶æ•°ï¼š{len(file_list)}ï¼‰")
        print(f"="*60)
        
        # åˆ›å»ºçº¿ç¨‹æ± å¹¶æäº¤ä»»åŠ¡ï¼ˆç¡®ä¿æ¯ä¸ªä»»åŠ¡ä»…ä¼ å…¥ä¸‰å…ƒç»„file_infoï¼‰
        with ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:
            futures = {
                executor.submit(RAWDysPeechProcessor.copy_single_file, info): info 
                for info in file_list
            }
            
            # éå†ä»»åŠ¡ç»“æœï¼ˆé€ä¸ªå¤„ç†ï¼Œé¿å…å¹¶å‘æ—¥å¿—æ··ä¹±ï¼‰
            for future in as_completed(futures):
                try:
                    result = future.result()  # è·å–ä»»åŠ¡ç»“æœï¼ˆå·²ä¿®å¤è§£åŒ…é—®é¢˜ï¼‰
                    status, label, filename, msg = result
                except Exception as e:
                    # æ•è·ä»»åŠ¡æ‰§è¡Œä¸­çš„æ„å¤–å¼‚å¸¸
                    info = futures[future]
                    filename = info[2]
                    label = info[1]
                    status = "fail"
                    msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)[:50]}..."
                    result = (status, label, filename, msg)
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if status == "success":
                    stats["success"] += 1
                    stats["class_count"][label] += 1
                    print(f"ğŸ“¤ æˆåŠŸ | {Config.CLASS_NAMES[label]} | {filename} | {msg}")
                elif status == "skip_identical":
                    stats["skip_identical"] += 1
                    print(f"â­ï¸  è·³è¿‡ | {Config.CLASS_NAMES[label]} | {filename} | {msg}")
                elif status == "fail":
                    stats["fail"] += 1
                    stats["fail_files"].append((filename, msg))
                    print(f"âŒ å¤±è´¥ | {Config.CLASS_NAMES[label]} | {filename} | {msg}")
        
        return stats
    
    @classmethod
    def process_dataset(cls):
        """RAWDysPeechæ•°æ®é›†å¤„ç†ä¸»å…¥å£ï¼šä¿®å¤è§£åŒ…å¼‚å¸¸ï¼Œç¨³å®šå¤šçº¿ç¨‹å¤åˆ¶"""
        try:
            print("="*70)
            print("å¼€å§‹å¤„ç†RAWDysPeechæ•°æ®é›†ï¼ˆå¤šçº¿ç¨‹åŠ é€Ÿç‰ˆÂ·ä¿®å¤è§£åŒ…å¼‚å¸¸ï¼‰")
            print("="*70)
            print(f"å½“å‰æœåŠ¡å™¨CPUæ ¸å¿ƒæ•°ï¼š{multiprocessing.cpu_count()}ï¼Œé…ç½®çº¿ç¨‹æ•°ï¼š{Config.MAX_WORKERS}")
            
            # 1. æ£€æŸ¥æºæ–‡ä»¶å¤¹å¹¶åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
            cls.create_target_directories()
            
            # 2. æ”¶é›†æ‰€æœ‰å¸¦æ ‡ç­¾çš„WAVæ–‡ä»¶åˆ—è¡¨ï¼ˆç¡®ä¿ä¸ºä¸‰å…ƒç»„ç»“æ„ï¼‰
            labeled_file_list = cls.get_labeled_file_list()
            
            # 3. å¤šçº¿ç¨‹å¤åˆ¶æ–‡ä»¶ï¼ˆä¿®å¤åæ—  unpack å¼‚å¸¸ï¼‰
            copy_stats = cls.multi_thread_copy(labeled_file_list)
            
            # 4. è¾“å‡ºæœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š
            print(f"\n" + "="*70)
            print("RAWDysPeechæ•°æ®é›†å¤„ç†å®Œæˆç»Ÿè®¡æŠ¥å‘Š")
            print("="*70)
            print(f"æ€»æ–‡ä»¶æ•°ï¼š{len(labeled_file_list)}")
            print(f"æˆåŠŸå¤åˆ¶ï¼š{copy_stats['success']} ä¸ª")
            print(f"è·³è¿‡é‡å¤ï¼š{copy_stats['skip_identical']} ä¸ªï¼ˆå†…å®¹å®Œå…¨ç›¸åŒï¼‰")
            print(f"å¤åˆ¶å¤±è´¥ï¼š{copy_stats['fail']} ä¸ª")
            print(f"\nå„ç±»åˆ«æˆåŠŸå¤åˆ¶æ•°é‡ï¼š")
            for label in [0, 1]:
                print(f"   - {Config.CLASS_NAMES[label]}ï¼š{copy_stats['class_count'][label]} ä¸ª")
            
            # è¾“å‡ºå¤±è´¥æ–‡ä»¶è¯¦æƒ…ï¼ˆè‹¥æœ‰ï¼‰
            if copy_stats['fail_files']:
                print(f"\nâŒ å¤åˆ¶å¤±è´¥æ–‡ä»¶è¯¦æƒ…ï¼ˆå…±{len(copy_stats['fail_files'])}ä¸ªï¼‰ï¼š")
                for idx, (filename, err_msg) in enumerate(copy_stats['fail_files'], 1):
                    print(f"   {idx}. {filename}ï¼š{err_msg}")
            
            print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼ç›®æ ‡ç›®å½•ï¼š{Config.DESTINATION_ROOT}")
            print("="*70)
        
        except Exception as main_e:
            print(f"\nâŒ RAWDysPeechæ•°æ®é›†å¤„ç†å¤±è´¥ï¼š{str(main_e)}")
            raise  # æŠ›å‡ºå¼‚å¸¸ä¾¿äºå®šä½é—®é¢˜
            return 1

if __name__ == "__main__":
    RAWDysPeechProcessor.process_dataset()