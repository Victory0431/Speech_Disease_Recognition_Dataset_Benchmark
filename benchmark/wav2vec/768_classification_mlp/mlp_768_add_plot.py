import os
import numpy as np
import torch
import torch.nn as nn
import pandas as pd
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)
from imblearn.over_sampling import SMOTE  # è¿‡é‡‡æ ·åº“
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")
import seaborn as sns

# ===================== 1. é…ç½®å‚æ•°ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰ =====================
class Config:
    # æ ¸å¿ƒè·¯å¾„
    FEAT_ROOT = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/768_npy_charactristic"  # ç‰¹å¾æ–‡ä»¶ç›®å½•
    SAVE_MODEL_DIR = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/768_classification_mlp/mlp_rid_healthy"  # æœ€ä¼˜æ¨¡å‹ä¿å­˜ç›®å½•
    PLOT_DIR = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/768_classification_mlp/mlp_cut_in_200"  # æ··æ·†çŸ©é˜µç­‰å›¾è¡¨ä¿å­˜ç›®å½•
    SAVE_MODEL_DIR = PLOT_DIR
    
    # è®­ç»ƒå‚æ•°
    BATCH_SIZE = 64        # æ‰¹æ¬¡å¤§å°ï¼ˆRTX 4090å¯è®¾64-128ï¼‰
    EPOCHS = 50            # è®­ç»ƒè½®æ¬¡
    LEARNING_RATE = 1e-4   # å­¦ä¹ ç‡
    WEIGHT_DECAY = 1e-5    # æƒé‡è¡°å‡ï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
    DROPOUT = 0.3          # Dropoutæ¯”ä¾‹
    DEVICE = torch.device("cuda:5" if torch.cuda.is_available() else "cpu")  # GPUè®¾å¤‡
    
    # æ•°æ®å¤„ç†å‚æ•°
    TEST_SIZE = 0.2        # æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆ8:2åˆ’åˆ†ï¼‰
    RANDOM_STATE = 42      # éšæœºç§å­ï¼ˆä¿è¯ç»“æœå¯å¤ç°ï¼‰
    N_SMOTE_NEIGHBORS = 5  # SMOTEè¿‡é‡‡æ ·çš„è¿‘é‚»æ•°ï¼ˆé»˜è®¤5ï¼Œå°æ ·æœ¬ç±»åˆ«å¯å‡å°è‡³3ï¼‰
    
    # è¯„ä¼°å‚æ•°
    EVAL_METRIC = "weighted"  # æŒ‡æ ‡è®¡ç®—æ–¹å¼ï¼ˆweighted=è€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡ï¼‰
    PLOT_CONFUSION_MATRIX = True  # æ˜¯å¦ç»˜åˆ¶æ··æ·†çŸ©é˜µ

    OVERSAMPLING_STRATEGY = "smote"  # å¯é€‰ "smote"ï¼ˆåˆæˆé‡‡æ ·ï¼‰æˆ– "resample"ï¼ˆé‡å¤é‡‡æ ·ï¼‰
    MAX_SAMPLES_PER_CLASS = 200      # æ¯ç±»è¿‡é‡‡æ ·åçš„æœ€å¤§æ ·æœ¬æ•°ï¼ˆå¯æ ¹æ®å®éªŒè°ƒæ•´ï¼‰


# åˆ›å»ºå¿…è¦ç›®å½•
os.makedirs(Config.SAVE_MODEL_DIR, exist_ok=True)
os.makedirs(Config.PLOT_DIR, exist_ok=True)


# ===================== 2. æ•°æ®åŠ è½½ä¸æ ‡ç­¾å¤„ç†ï¼ˆæ ¸å¿ƒï¼šæŒ‰æ–‡ä»¶åè§£æç±»åˆ«ï¼‰ =====================
def parse_class_from_filename(filename):
    """ä»ç‰¹å¾æ–‡ä»¶åè§£æç±»åˆ«ï¼ˆæ ¼å¼ï¼šæ•°æ®é›†å__and__ç±»åˆ«å.npyï¼‰"""
    # å»æ‰.npyåç¼€ï¼ŒæŒ‰"__and__"æ‹†åˆ†
    prefix = filename.replace(".npy", "")
    if "__and__" not in prefix:
        raise ValueError(f"æ–‡ä»¶åæ ¼å¼é”™è¯¯ï¼ˆéœ€ä¸ºã€Œæ•°æ®é›†å__and__ç±»åˆ«å.npyã€ï¼‰ï¼š{filename}")
    dataset_name, class_name = prefix.split("__and__", 1)  # ä»…æ‹†åˆ†ä¸€æ¬¡ï¼ˆé¿å…ç±»åˆ«åå«"__and__"ï¼‰
    return dataset_name, class_name


def load_all_features_and_labels(feat_root):
    """åŠ è½½æ‰€æœ‰ç‰¹å¾æ–‡ä»¶ï¼Œç”Ÿæˆæ ‡ç­¾æ˜ å°„ï¼ˆæ¯ä¸ªæ–‡ä»¶å¯¹åº”ä¸€ä¸ªç±»åˆ«ï¼‰"""
    print(f"ğŸ“Š ä» {feat_root} åŠ è½½ç‰¹å¾æ–‡ä»¶...")
    
    # 1. éå†ç›®å½•ï¼Œç­›é€‰ç‰¹å¾æ–‡ä»¶ï¼ˆå¿½ç•¥_labels.npyæ ‡ç­¾æ–‡ä»¶ï¼‰
    feat_files = []
    for f in os.listdir(feat_root):
        # å¿½ç•¥æ ‡ç­¾æ–‡ä»¶ï¼Œåªä¿ç•™ç‰¹å¾æ–‡ä»¶ï¼ˆæ ¼å¼ï¼šXXX__and__XXX.npyï¼‰
        if f.endswith(".npy") and "_labels.npy" not in f and 'Healthy' not in f and 'healthy' not in f:
            feat_files.append(f)
            # å°šæœ‰Nonæ‹“å±•ç©ºé—´
    
    if len(feat_files) == 0:
        raise FileNotFoundError(f"âŒ åœ¨ {feat_root} æœªæ‰¾åˆ°æœ‰æ•ˆç‰¹å¾æ–‡ä»¶ï¼ˆéœ€ä¸ºã€Œæ•°æ®é›†å__and__ç±»åˆ«å.npyã€æ ¼å¼ï¼‰")
    
    # 2. ç”Ÿæˆç±»åˆ«æ˜ å°„ï¼ˆæ¯ä¸ªç±»åˆ«åˆ†é…å”¯ä¸€IDï¼‰
    all_classes = []
    for f in feat_files:
        dataset_name, class_name = parse_class_from_filename(f)
        all_classes.append(dataset_name+'_and_'+class_name)
    unique_classes = sorted(list(set(all_classes)))  # å»é‡å¹¶æ’åºï¼ˆä¿è¯IDç¨³å®šï¼‰
    class2id = {cls: idx for idx, cls in enumerate(unique_classes)}
    num_classes = len(unique_classes)
    print(f"âœ… ç”Ÿæˆç±»åˆ«æ˜ å°„ï¼šå…± {num_classes} ä¸ªç±»åˆ«")
    for cls, idx in class2id.items():
        print(f"   - ç±»åˆ«ï¼š{cls} â†’ IDï¼š{idx}")
    
    # 3. åŠ è½½ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆæ¯ä¸ªæ–‡ä»¶çš„æ‰€æœ‰æ ·æœ¬å¯¹åº”åŒä¸€ç±»åˆ«ï¼‰
    all_feats = []
    all_labels = []
    all_metadata = []  # å¯é€‰ï¼šè®°å½•æ ·æœ¬æ¥è‡ªå“ªä¸ªæ–‡ä»¶
    
    for f in tqdm(feat_files, desc="åŠ è½½ç‰¹å¾æ–‡ä»¶"):
        file_path = os.path.join(feat_root, f)
        dataset_name, class_name = parse_class_from_filename(f)
        class_name = dataset_name + '_and_' + class_name
        current_label = class2id[class_name]
        
        # åŠ è½½ç‰¹å¾ï¼ˆå½¢çŠ¶ï¼š[æ ·æœ¬æ•°, 768]ï¼‰
        feats = np.load(file_path).astype(np.float32)
        if feats.shape[1] != 768:
            raise ValueError(f"âŒ {f} ç‰¹å¾ç»´åº¦é”™è¯¯ï¼ˆéœ€ä¸º768ç»´ï¼‰ï¼Œå®é™…ç»´åº¦ï¼š{feats.shape[1]}")
        
        # æ”¶é›†ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆè¯¥æ–‡ä»¶æ‰€æœ‰æ ·æœ¬æ ‡ç­¾ç›¸åŒï¼‰
        all_feats.append(feats)
        all_labels.extend([current_label] * feats.shape[0])  # æ¯ä¸ªæ ·æœ¬å¯¹åº”åŒä¸€ç±»åˆ«
        all_metadata.extend([(dataset_name, class_name)] * feats.shape[0])  # å¯é€‰ï¼šè®°å½•å…ƒä¿¡æ¯
    
    # 4. æ‹¼æ¥ä¸ºå…¨å±€æ•°ç»„
    all_feats = np.concatenate(all_feats, axis=0)  # [æ€»æ ·æœ¬æ•°, 768]
    all_labels = np.array(all_labels, dtype=np.int64)  # [æ€»æ ·æœ¬æ•°]
    
    print(f"\nğŸ“ˆ æ•°æ®åŠ è½½å®Œæˆï¼š")
    print(f"   - æ€»æ ·æœ¬æ•°ï¼š{all_feats.shape[0]}")
    print(f"   - ç‰¹å¾ç»´åº¦ï¼š{all_feats.shape[1]}")
    print(f"   - ç±»åˆ«æ•°ï¼š{num_classes}")
    print(f"   - ç±»åˆ«åˆ†å¸ƒï¼š")
    for cls, idx in class2id.items():
        cnt = np.sum(all_labels == idx)
        print(f"     * {cls}ï¼š{cnt} ä¸ªæ ·æœ¬ï¼ˆ{cnt/all_labels.shape[0]*100:.1f}%ï¼‰")
    
    return all_feats, all_labels, class2id, unique_classes


# ===================== 3. æ•°æ®é¢„å¤„ç†ï¼ˆåˆ’åˆ†+å½’ä¸€åŒ–+è¿‡é‡‡æ ·ï¼‰ =====================
def preprocess_data_v1(all_feats, all_labels):
    """
    æ•°æ®é¢„å¤„ç†æµç¨‹ï¼š
    1. 8:2åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆä¿è¯ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼‰
    2. åŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡åšå½’ä¸€åŒ–ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
    3. è®­ç»ƒé›†è¿‡é‡‡æ ·ï¼ˆSMOTEï¼‰è§£å†³ç±»åˆ«ä¸å¹³è¡¡
    """
    print(f"\nğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
    # 1. åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆstratify=all_labels ä¿è¯ç±»åˆ«åˆ†å¸ƒï¼‰
    train_feat, test_feat, train_label, test_label = train_test_split(
        all_feats, all_labels,
        test_size=Config.TEST_SIZE,
        stratify=all_labels,
        random_state=Config.RANDOM_STATE
    )
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†ï¼š{train_feat.shape[0]} æ ·æœ¬")
    print(f"   - æµ‹è¯•é›†ï¼š{test_feat.shape[0]} æ ·æœ¬")
    
    # 2. åŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡åšå½’ä¸€åŒ–ï¼ˆZ-Scoreï¼šå‡å€¼=0ï¼Œæ ‡å‡†å·®=1ï¼‰
    # æŒ‰ç‰¹å¾ç»´åº¦è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆ768ä¸ªç»´åº¦å„1ä¸ªç»Ÿè®¡é‡ï¼‰
    train_mean = np.mean(train_feat, axis=0)  # [768]
    train_std = np.std(train_feat, axis=0)    # [768]
    # é¿å…æ ‡å‡†å·®ä¸º0å¯¼è‡´é™¤ä»¥0ï¼ˆåŠ æå°å€¼1e-8ï¼‰
    train_std = np.where(train_std < 1e-8, 1e-8, train_std)
    
    # å½’ä¸€åŒ–è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆæµ‹è¯•é›†ç”¨è®­ç»ƒé›†ç»Ÿè®¡é‡ï¼ï¼‰
    train_feat_norm = (train_feat - train_mean) / train_std
    test_feat_norm = (test_feat - train_mean) / train_std
    
    print(f"âœ… å½’ä¸€åŒ–å®Œæˆï¼ˆåŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡ï¼‰ï¼š")
    print(f"   - è®­ç»ƒé›†å½’ä¸€åŒ–å‰èŒƒå›´ï¼š[{train_feat.min():.4f}, {train_feat.max():.4f}]")
    print(f"   - è®­ç»ƒé›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{train_feat_norm.min():.4f}, {train_feat_norm.max():.4f}]")
    print(f"   - æµ‹è¯•é›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{test_feat_norm.min():.4f}, {test_feat_norm.max():.4f}]")
    
    # 3. è®­ç»ƒé›†è¿‡é‡‡æ ·ï¼ˆSMOTEï¼‰ï¼šä»…å¯¹è®­ç»ƒé›†åšï¼Œæµ‹è¯•é›†ä¿æŒåŸå§‹
    print(f"\nâš–ï¸ å¼€å§‹è®­ç»ƒé›†è¿‡é‡‡æ ·ï¼ˆSMOTEï¼‰...")
    print(f"   - è¿‡é‡‡æ ·å‰è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    for idx in np.unique(train_label):
        cnt = np.sum(train_label == idx)
        print(f"     * ç±»åˆ«{idx}ï¼š{cnt} æ ·æœ¬")
    
    # åˆå§‹åŒ–SMOTEï¼ˆè¿‘é‚»æ•°æ ¹æ®å°æ ·æœ¬ç±»åˆ«è°ƒæ•´ï¼‰
    smote = SMOTE(
        k_neighbors=Config.N_SMOTE_NEIGHBORS,
        random_state=Config.RANDOM_STATE
    )
    # è¿‡é‡‡æ ·ï¼ˆç”Ÿæˆåˆæˆæ ·æœ¬ï¼Œå¹³è¡¡ç±»åˆ«ï¼‰
    train_feat_smote, train_label_smote = smote.fit_resample(train_feat_norm, train_label)
    
    print(f"   - è¿‡é‡‡æ ·åè®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    for idx in np.unique(train_label_smote):
        cnt = np.sum(train_label_smote == idx)
        print(f"     * ç±»åˆ«{idx}ï¼š{cnt} æ ·æœ¬")
    print(f"   - è¿‡é‡‡æ ·åè®­ç»ƒé›†æ€»æ ·æœ¬æ•°ï¼š{train_feat_smote.shape[0]}")
    
    # è¿”å›é¢„å¤„ç†åçš„æ•°æ®
    return (
        train_feat_smote, train_label_smote,  # è¿‡é‡‡æ ·åçš„è®­ç»ƒé›†
        test_feat_norm, test_label,           # å½’ä¸€åŒ–åçš„æµ‹è¯•é›†
        train_mean, train_std                 # å½’ä¸€åŒ–ç»Ÿè®¡é‡ï¼ˆåç»­æ¨ç†ç”¨ï¼‰
    )


# ===================== 3. æ•°æ®é¢„å¤„ç†ï¼ˆåˆ’åˆ†+å½’ä¸€åŒ–+è¿‡é‡‡æ ·ï¼‰ =====================
def preprocess_data(all_feats, all_labels):
    """
    ç»å…¸æ•°æ®é¢„å¤„ç†æµç¨‹ï¼š
    1. åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†
    2. å½’ä¸€åŒ–ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
    3. è¿‡é‡‡æ ·ï¼šå¤šæ•°ç±»ä¸‹é‡‡æ ·åˆ°ä¸Šé™ï¼Œå°‘æ•°ç±»SMOTEè¿‡é‡‡æ ·åˆ°ä¸Šé™ï¼ˆç»å…¸å¹³è¡¡ç­–ç•¥ï¼‰
    """
    print(f"\nğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
    # 1. åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†
    from sklearn.model_selection import train_test_split
    train_feat, test_feat, train_label, test_label = train_test_split(
        all_feats, all_labels,
        test_size=Config.TEST_SIZE,
        stratify=all_labels,
        random_state=Config.RANDOM_STATE
    )
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†ï¼š{train_feat.shape[0]} æ ·æœ¬")
    print(f"   - æµ‹è¯•é›†ï¼š{test_feat.shape[0]} æ ·æœ¬")
    
    # 2. å½’ä¸€åŒ–ï¼ˆZ-Scoreï¼‰
    train_mean = np.mean(train_feat, axis=0)
    train_std = np.std(train_feat, axis=0)
    train_std = np.where(train_std < 1e-8, 1e-8, train_std)  # é¿å…é™¤é›¶
    
    train_feat_norm = (train_feat - train_mean) / train_std
    test_feat_norm = (test_feat - train_mean) / train_std
    
    print(f"âœ… å½’ä¸€åŒ–å®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{train_feat_norm.min():.4f}, {train_feat_norm.max():.4f}]")
    print(f"   - æµ‹è¯•é›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{test_feat_norm.min():.4f}, {test_feat_norm.max():.4f}]")
    
    # 3. ç»å…¸è¿‡é‡‡æ ·ç­–ç•¥ï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·+å°‘æ•°ç±»SMOTEï¼‰
    print(f"\nâš–ï¸ å¼€å§‹è¿‡é‡‡æ ·ï¼ˆæ¯ç±»é™åˆ¶æœ€å¤§{Config.MAX_SAMPLES_PER_CLASS}æ ·æœ¬ï¼‰...")
    print(f"   - è¿‡é‡‡æ ·å‰åˆ†å¸ƒï¼š")
    unique_labels = np.unique(train_label)
    for label in unique_labels:
        print(f"     * ç±»åˆ«{label}ï¼š{np.sum(train_label == label)} æ ·æœ¬")
    
    # æ­¥éª¤1ï¼šå¯¹æ‰€æœ‰ç±»åˆ«å…ˆæˆªæ–­åˆ°æœ€å¤§æ ·æœ¬æ•°ï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·ï¼‰
    from collections import defaultdict
    np.random.seed(Config.RANDOM_STATE)  # å…¨å±€è®¾ç½®éšæœºç§å­ï¼ˆæ›¿ä»£random_stateå‚æ•°ï¼‰
    class_data = defaultdict(list)
    
    # æŒ‰ç±»åˆ«æ”¶é›†æ•°æ®
    for feat, label in zip(train_feat_norm, train_label):
        class_data[label].append(feat)
    
    # æˆªæ–­å¤šæ•°ç±»
    truncated_data = []
    truncated_labels = []
    for label in class_data:
        samples = np.array(class_data[label])
        n_samples = len(samples)
        
        if n_samples > Config.MAX_SAMPLES_PER_CLASS:
            # å¤šæ•°ç±»ï¼šéšæœºä¸‹é‡‡æ ·åˆ°ä¸Šé™
            selected_idx = np.random.choice(n_samples, Config.MAX_SAMPLES_PER_CLASS, replace=False)
            truncated_samples = samples[selected_idx]
        else:
            # å°‘æ•°ç±»ï¼šä¿ç•™å…¨éƒ¨æ ·æœ¬
            truncated_samples = samples
        
        truncated_data.append(truncated_samples)
        truncated_labels.append(np.full(len(truncated_samples), label))
    
    # åˆå¹¶æˆªæ–­åçš„æ•°æ®
    truncated_data = np.concatenate(truncated_data, axis=0)
    truncated_labels = np.concatenate(truncated_labels, axis=0)
    
    # æ­¥éª¤2ï¼šå¯¹å°‘æ•°ç±»ä½¿ç”¨SMOTEè¿‡é‡‡æ ·ï¼ˆè¡¥åˆ°æœ€å¤§æ ·æœ¬æ•°ï¼‰
    from imblearn.over_sampling import SMOTE
    # è®¡ç®—æ¯ä¸ªç±»åˆ«éœ€è¦è¾¾åˆ°çš„æ ·æœ¬æ•°
    sampling_strategy = {
        label: Config.MAX_SAMPLES_PER_CLASS 
        for label in unique_labels
    }
    
    # å¤„ç†å•ç±»åˆ«ç‰¹æ®Šæƒ…å†µ
    if len(unique_labels) == 1:
        print(f"âš ï¸ ä»…1ä¸ªç±»åˆ«ï¼Œæ— éœ€SMOTEï¼Œä½¿ç”¨æˆªæ–­åæ•°æ®")
        train_feat_smote = truncated_data
        train_label_smote = truncated_labels
    else:
        # ç»å…¸SMOTEåº”ç”¨ï¼ˆå¯¹æ•´ä¸ªæ•°æ®é›†å¤„ç†ï¼Œé¿å…å•ç±»åˆ«é”™è¯¯ï¼‰
        smote = SMOTE(
            sampling_strategy=sampling_strategy,
            k_neighbors=min(5, min(np.bincount(truncated_labels)) - 1),  # å®‰å…¨çš„è¿‘é‚»æ•°
            random_state=Config.RANDOM_STATE
        )
        train_feat_smote, train_label_smote = smote.fit_resample(truncated_data, truncated_labels)
    
    # è¾“å‡ºè¿‡é‡‡æ ·ç»“æœ
    print(f"   - è¿‡é‡‡æ ·ååˆ†å¸ƒï¼š")
    for label in np.unique(train_label_smote):
        print(f"     * ç±»åˆ«{label}ï¼š{np.sum(train_label_smote == label)} æ ·æœ¬")
    print(f"   - æ€»æ ·æœ¬æ•°ï¼š{train_feat_smote.shape[0]}")
    
    return (
        train_feat_smote, train_label_smote,
        test_feat_norm, test_label,
        train_mean, train_std
    )


# ===================== 4. æ•°æ®é›†ä¸DataLoaderå®šä¹‰ =====================
class MLPFeatDataset(Dataset):
    """ç‰¹å¾æ•°æ®é›†ï¼šé€‚é…PyTorch DataLoader"""
    def __init__(self, feats, labels):
        self.feats = torch.tensor(feats, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)
        assert len(self.feats) == len(self.labels), "ç‰¹å¾ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…ï¼"
    
    def __len__(self):
        return len(self.feats)
    
    def __getitem__(self, idx):
        return {"feat": self.feats[idx], "label": self.labels[idx]}


def create_dataloaders(train_feat, train_label, test_feat, test_label):
    """åˆ›å»ºè®­ç»ƒé›†/æµ‹è¯•é›†DataLoaderï¼ˆè®­ç»ƒé›†æ‰“ä¹±ï¼Œæµ‹è¯•é›†ä¸æ‰“ä¹±ï¼‰"""
    train_dataset = MLPFeatDataset(train_feat, train_label)
    test_dataset = MLPFeatDataset(test_feat, test_label)
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=True,  # è®­ç»ƒé›†æ‰“ä¹±
        drop_last=True,  # ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´æ‰¹æ¬¡
        pin_memory=True  # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,  # æµ‹è¯•é›†ä¸æ‰“ä¹±
        pin_memory=True
    )
    
    print(f"\nğŸš€ DataLoaderåˆ›å»ºå®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†æ‰¹æ¬¡ï¼š{len(train_loader)} æ‰¹ï¼ˆæ¯æ‰¹{Config.BATCH_SIZE}æ ·æœ¬ï¼‰")
    print(f"   - æµ‹è¯•é›†æ‰¹æ¬¡ï¼š{len(test_loader)} æ‰¹ï¼ˆæ¯æ‰¹{Config.BATCH_SIZE}æ ·æœ¬ï¼‰")
    
    return train_loader, test_loader


# ===================== 5. MLPåˆ†ç±»æ¨¡å‹å®šä¹‰ï¼ˆé€‚é…768ç»´è¾“å…¥ï¼‰ =====================
class MLPClassifier(nn.Module):
    """è½»é‡çº§MLPåˆ†ç±»å™¨ï¼šè¾“å…¥768ç»´ç‰¹å¾ï¼Œè¾“å‡ºç±»åˆ«æ¦‚ç‡"""
    def __init__(self, input_dim=768, num_classes=2, dropout=Config.DROPOUT):
        super().__init__()
        self.classifier = nn.Sequential(
            # ç¬¬ä¸€å±‚ï¼š768â†’512ï¼ŒReLUæ¿€æ´»+Dropout
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            # ç¬¬äºŒå±‚ï¼š512â†’256ï¼ŒReLUæ¿€æ´»+Dropout
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            # è¾“å‡ºå±‚ï¼š256â†’ç±»åˆ«æ•°ï¼ˆæ— æ¿€æ´»ï¼ŒCrossEntropyLossè‡ªå¸¦Softmaxï¼‰
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        """x: [batch_size, 768] â†’ logits: [batch_size, num_classes]"""
        return self.classifier(x)


# ===================== 6. è®­ç»ƒä¸è¯„ä¼°å‡½æ•°ï¼ˆä¿ç•™åŸåŠŸèƒ½ï¼Œä¼˜åŒ–æŒ‡æ ‡è¿”å›ï¼‰ =====================
def train_one_epoch(model, dataloader, criterion, optimizer, scaler):
    """è®­ç»ƒä¸€è½®ï¼Œè¿”å›è®­ç»ƒé›†å…¨æŒ‡æ ‡ï¼ˆæŸå¤±+å‡†ç¡®ç‡+ç²¾ç¡®ç‡+å¬å›ç‡+F1ï¼‰"""
    model.train()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    
    for batch in tqdm(dataloader, desc="è®­ç»ƒä¸­"):
        feats = batch["feat"].to(Config.DEVICE)
        labels = batch["label"].to(Config.DEVICE)
        
        optimizer.zero_grad()
        with autocast():
            logits = model(feats)
            loss = criterion(logits, labels)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        # ç´¯è®¡æŸå¤±å’Œé¢„æµ‹ç»“æœ
        total_loss += loss.item() * feats.size(0)
        preds = torch.argmax(logits, dim=1).cpu().numpy()
        all_preds.extend(preds)
        all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—è®­ç»ƒé›†å…¨æŒ‡æ ‡
    avg_loss = total_loss / len(dataloader.dataset)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average=Config.EVAL_METRIC, zero_division=0)
    recall = recall_score(all_labels, all_preds, average=Config.EVAL_METRIC, zero_division=0)
    f1 = f1_score(all_labels, all_preds, average=Config.EVAL_METRIC, zero_division=0)
    
    return avg_loss, accuracy, precision, recall, f1


def evaluate_model(model, dataloader, criterion, class2id, is_test=False):
    """è¯„ä¼°æ¨¡å‹ï¼Œè¿”å›å…¨æŒ‡æ ‡ï¼ˆæŸå¤±+å‡†ç¡®ç‡+ç²¾ç¡®ç‡+å¬å›ç‡+F1ï¼‰ï¼Œæµ‹è¯•é›†è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
    model.eval()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="è¯„ä¼°ä¸­"):
            feats = batch["feat"].to(Config.DEVICE)
            labels = batch["label"].to(Config.DEVICE)
            
            with autocast():
                logits = model(feats)
                loss = criterion(logits, labels)
            
            total_loss += loss.item() * feats.size(0)
            preds = torch.argmax(logits, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—å…¨æŒ‡æ ‡
    avg_loss = total_loss / len(dataloader.dataset)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average=Config.EVAL_METRIC, zero_division=0)
    recall = recall_score(all_labels, all_preds, average=Config.EVAL_METRIC, zero_division=0)
    f1 = f1_score(all_labels, all_preds, average=Config.EVAL_METRIC, zero_division=0)
    
    # æµ‹è¯•é›†é¢å¤–è¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
    if is_test:
        print(f"\n========== æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°ç»“æœ ==========")
        print(f"1. æ€»ä½“æŒ‡æ ‡ï¼ˆ{Config.EVAL_METRIC}å¹³å‡ï¼‰ï¼š")
        print(f"   - æŸå¤±ï¼š{avg_loss:.4f}")
        print(f"   - å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š{accuracy:.4f}")
        print(f"   - ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼š{precision:.4f}")
        print(f"   - å¬å›ç‡ï¼ˆRecallï¼‰ï¼š{recall:.4f}")
        print(f"   - F1åˆ†æ•°ï¼š{f1:.4f}\n")
        
        # è¾“å‡ºå„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡
        id2class = {idx: cls for cls, idx in class2id.items()}
        class_prec = precision_score(all_labels, all_preds, average=None, zero_division=0)
        class_rec = recall_score(all_labels, all_preds, average=None, zero_division=0)
        class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)
        
        print(f"2. å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡ï¼š")
        for idx in np.unique(all_labels):
            cls_name = id2class[idx]
            print(f"   - {cls_name}ï¼ˆID:{idx}ï¼‰ï¼š")
            print(f"     ç²¾ç¡®ç‡ï¼š{class_prec[idx]:.4f} | å¬å›ç‡ï¼š{class_rec[idx]:.4f} | F1ï¼š{class_f1[idx]:.4f}")
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
        if Config.PLOT_CONFUSION_MATRIX:
            cm = confusion_matrix(all_labels, all_preds)
            plt.figure(figsize=(12 + len(class2id)//5, 10 + len(class2id)//5))  # æŒ‰ç±»åˆ«æ•°è‡ªé€‚åº”å°ºå¯¸
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']  # é¿å…ä¸­æ–‡ä¹±ç ï¼ˆé€‚é…ç±»åˆ«åå«è‹±æ–‡ï¼‰
            
            sns.heatmap(
                cm, 
                annot=True, 
                fmt="d", 
                cmap="Blues",
                xticklabels=[id2class[idx] for idx in range(len(class2id))],
                yticklabels=[id2class[idx] for idx in range(len(class2id))],
                annot_kws={"fontsize": 6 if len(class2id) > 10 else 8}  # ç±»åˆ«å¤šåˆ™ç¼©å°å­—ä½“
            )
            plt.xlabel("Predicted Class", fontsize=12)
            plt.ylabel("True Class", fontsize=12)
            plt.title("Test Set Confusion Matrix", fontsize=14, pad=20)
            plt.xticks(rotation=45 if len(class2id) <= 15 else 90, ha="right")  # ç±»åˆ«å¤šåˆ™æ—‹è½¬90åº¦
            plt.tight_layout()
            cm_save_path = os.path.join(Config.PLOT_DIR, "test_confusion_matrix.png")
            plt.savefig(cm_save_path, dpi=300, bbox_inches="tight")
            plt.close()
            print(f"\n3. æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³ï¼š{cm_save_path}")
    
    return avg_loss, accuracy, precision, recall, f1


# ===================== æ–°å¢ï¼šæ—¥å¿—ä¿å­˜ä¸ç»˜å›¾å‡½æ•° =====================
def save_training_logs(logs, save_dir):
    """å°†è®­ç»ƒæ—¥å¿—ï¼ˆæ¯è½®æŒ‡æ ‡ï¼‰ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
    # è½¬æ¢ä¸ºDataFrameï¼Œåˆ—åæ¸…æ™°
    log_df = pd.DataFrame(logs, columns=[
        "epoch", 
        "train_loss", "train_accuracy", "train_precision", "train_recall", "train_f1",
        "test_loss", "test_accuracy", "test_precision", "test_recall", "test_f1"
    ])
    # ä¿å­˜è·¯å¾„
    csv_path = os.path.join(save_dir, "mlp_training_logs.csv")
    log_df.to_csv(csv_path, index=False, encoding="utf-8")
    print(f"\nğŸ“„ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜è‡³ï¼š{csv_path}")
    return csv_path


def plot_loss_curve(logs, save_dir):
    """ç»˜åˆ¶è®­ç»ƒ/æµ‹è¯•æŸå¤±æ›²çº¿ï¼Œä¿å­˜ä¸ºå›¾ç‰‡"""
    epochs = [log["epoch"] for log in logs]
    train_loss = [log["train_loss"] for log in logs]
    test_loss = [log["test_loss"] for log in logs]
    
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_loss, label="Train Loss", color="#1f77b4", linewidth=2, marker="o", markersize=4)
    plt.plot(epochs, test_loss, label="Test Loss", color="#ff7f0e", linewidth=2, marker="s", markersize=4)
    
    # å›¾è¡¨ç¾åŒ–
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("Loss", fontsize=12)
    plt.title("MLP Training & Test Loss Curve", fontsize=14, pad=20)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.xticks(epochs[::max(1, len(epochs)//10)])  # æœ€å¤šæ˜¾ç¤º10ä¸ªåˆ»åº¦ï¼Œé¿å…æ‹¥æŒ¤
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    loss_plot_path = os.path.join(save_dir, "mlp_loss_curve.png")
    plt.savefig(loss_plot_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"ğŸ“Š æŸå¤±æ›²çº¿å·²ä¿å­˜è‡³ï¼š{loss_plot_path}")


def plot_accuracy_curve(logs, save_dir):
    """ç»˜åˆ¶è®­ç»ƒ/æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿ï¼Œä¿å­˜ä¸ºå›¾ç‰‡"""
    epochs = [log["epoch"] for log in logs]
    train_acc = [log["train_accuracy"] for log in logs]
    test_acc = [log["test_accuracy"] for log in logs]
    
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_acc, label="Train Accuracy", color="#2ca02c", linewidth=2, marker="o", markersize=4)
    plt.plot(epochs, test_acc, label="Test Accuracy", color="#d62728", linewidth=2, marker="s", markersize=4)
    
    # å›¾è¡¨ç¾åŒ–
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("Accuracy", fontsize=12)
    plt.title("MLP Training & Test Accuracy Curve", fontsize=14, pad=20)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1.05)  # å‡†ç¡®ç‡èŒƒå›´å›ºå®šä¸º0-1.05ï¼Œæ›´ç›´è§‚
    plt.xticks(epochs[::max(1, len(epochs)//10)])
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    acc_plot_path = os.path.join(save_dir, "mlp_accuracy_curve.png")
    plt.savefig(acc_plot_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"ğŸ“Š å‡†ç¡®ç‡æ›²çº¿å·²ä¿å­˜è‡³ï¼š{acc_plot_path}")


# ===================== 7. ä¸»å‡½æ•°ï¼ˆæ–°å¢æ—¥å¿—ä¿å­˜+ç»˜å›¾è°ƒç”¨ï¼‰ =====================
def main():
   
    
    all_feats, all_labels, class2id, unique_classes = load_all_features_and_labels(Config.FEAT_ROOT)
    num_classes = len(class2id)
    
    # Step 2ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
    (train_feat_smote, train_label_smote, 
     test_feat_norm, test_label, 
     train_mean, train_std) = preprocess_data(all_feats, all_labels)
    
    # Step 3ï¼šåˆ›å»ºDataLoaderï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
    train_loader, test_loader = create_dataloaders(
        train_feat_smote, train_label_smote,
        test_feat_norm, test_label
    )
    
    # Step 4ï¼šåˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
    model = MLPClassifier(
        input_dim=768,
        num_classes=num_classes,
        dropout=Config.DROPOUT
    ).to(Config.DEVICE)
    print(f"\nğŸ“Œ MLPæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆè®¾å¤‡ï¼š{Config.DEVICE}ï¼‰")
    print(f"   - è¾“å…¥ç»´åº¦ï¼š768")
    print(f"   - è¾“å‡ºç»´åº¦ï¼š{num_classes}ï¼ˆç±»åˆ«æ•°ï¼‰")
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(
        model.parameters(),
        lr=Config.LEARNING_RATE,
        weight_decay=Config.WEIGHT_DECAY
    )
    scaler = GradScaler()
    
    # ===================== æ–°å¢ï¼šåˆå§‹åŒ–è®­ç»ƒæ—¥å¿—åˆ—è¡¨ =====================
    train_logs = []  # å­˜å‚¨æ¯è½®çš„å…¨æŒ‡æ ‡
    best_test_f1 = 0.0
    
    # Step 5ï¼šè®­ç»ƒå¾ªç¯ï¼ˆæ–°å¢æŒ‡æ ‡è®°å½•ï¼‰
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼ˆå…±{Config.EPOCHS}è½®ï¼‰")
    for epoch in range(1, Config.EPOCHS + 1):
        print(f"\n===== Epoch {epoch}/{Config.EPOCHS} =====")
        
        # è®­ç»ƒä¸€è½®ï¼Œè·å–å…¨æŒ‡æ ‡
        train_loss, train_acc, train_prec, train_rec, train_f1 = train_one_epoch(
            model, train_loader, criterion, optimizer, scaler
        )
        
        # è¯„ä¼°æµ‹è¯•é›†ï¼Œè·å–å…¨æŒ‡æ ‡
        test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate_model(
            model, test_loader, criterion, class2id, is_test=False
        )
        
        # 1. æ‰“å°æ¯è½®å…¨æŒ‡æ ‡æ—¥å¿—
        print(f"ğŸ“Š è®­ç»ƒé›†ï¼š")
        print(f"   æŸå¤±ï¼š{train_loss:.4f} | å‡†ç¡®ç‡ï¼š{train_acc:.4f} | ç²¾ç¡®ç‡ï¼š{train_prec:.4f} | å¬å›ç‡ï¼š{train_rec:.4f} | F1ï¼š{train_f1:.4f}")
        print(f"ğŸ“Š æµ‹è¯•é›†ï¼š")
        print(f"   æŸå¤±ï¼š{test_loss:.4f} | å‡†ç¡®ç‡ï¼š{test_acc:.4f} | ç²¾ç¡®ç‡ï¼š{test_prec:.4f} | å¬å›ç‡ï¼š{test_rec:.4f} | F1ï¼š{test_f1:.4f}")
        
        # 2. è®°å½•å½“å‰è½®æ¬¡æ—¥å¿—
        train_logs.append({
            "epoch": epoch,
            "train_loss": train_loss, "train_accuracy": train_acc, 
            "train_precision": train_prec, "train_recall": train_rec, "train_f1": train_f1,
            "test_loss": test_loss, "test_accuracy": test_acc,
            "test_precision": test_prec, "test_recall": test_rec, "test_f1": test_f1
        })
        
        # 3. ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
        if test_f1 > best_test_f1:
            best_test_f1 = test_f1
            save_path = os.path.join(Config.SAVE_MODEL_DIR, "best_model.pth")
            torch.save({
                "model_state_dict": model.state_dict(),
                "class2id": class2id,
                "train_mean": train_mean,
                "train_std": train_std
            }, save_path)
            print(f"âœ… ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆæµ‹è¯•é›†F1ï¼š{best_test_f1:.4f}ï¼‰è‡³ {save_path}")
    
    # ===================== æ–°å¢ï¼šè®­ç»ƒç»“æŸåä¿å­˜æ—¥å¿—+ç»˜åˆ¶å›¾è¡¨ =====================
    # 1. ä¿å­˜è®­ç»ƒæ—¥å¿—ä¸ºCSV
    save_training_logs(train_logs, Config.PLOT_DIR)
    
    # 2. ç»˜åˆ¶æŸå¤±æ›²çº¿
    plot_loss_curve(train_logs, Config.PLOT_DIR)
    
    # 3. ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    plot_accuracy_curve(train_logs, Config.PLOT_DIR)
    
    # Step 6ï¼šåŠ è½½æœ€ä¼˜æ¨¡å‹åšæœ€ç»ˆæµ‹è¯•ï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
    print(f"\n========== åŠ è½½æœ€ä¼˜æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯• ==========")
    checkpoint = torch.load(os.path.join(Config.SAVE_MODEL_DIR, "best_model.pth"))
    best_model = MLPClassifier(input_dim=768, num_classes=num_classes).to(Config.DEVICE)
    best_model.load_state_dict(checkpoint["model_state_dict"])
    evaluate_model(best_model, test_loader, criterion, class2id, is_test=True)
    
    print(f"\nğŸ‰ MLPå¤šç±»åˆ«åˆ†ç±»ä»»åŠ¡å®Œæˆï¼")
    print(f"   - æœ€ä¼˜æ¨¡å‹è·¯å¾„ï¼š{Config.SAVE_MODEL_DIR}/best_model.pth")
    print(f"   - è®­ç»ƒæ—¥å¿—è·¯å¾„ï¼š{os.path.join(Config.PLOT_DIR, 'mlp_training_logs.csv')}")
    print(f"   - æŸå¤±æ›²çº¿è·¯å¾„ï¼š{os.path.join(Config.PLOT_DIR, 'mlp_loss_curve.png')}")
    print(f"   - å‡†ç¡®ç‡æ›²çº¿è·¯å¾„ï¼š{os.path.join(Config.PLOT_DIR, 'mlp_accuracy_curve.png')}")
    if Config.PLOT_CONFUSION_MATRIX:
        print(f"   - æ··æ·†çŸ©é˜µè·¯å¾„ï¼š{os.path.join(Config.PLOT_DIR, 'test_confusion_matrix.png')}")


if __name__ == "__main__":
    main()