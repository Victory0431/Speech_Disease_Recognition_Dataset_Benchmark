import os
import numpy as np
import torch
import torch.nn as nn
import pandas as pd
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
from torch.utils.tensorboard import SummaryWriter
import argparse  # æ–°å¢ï¼šå‘½ä»¤è¡Œå‚æ•°è§£æ

warnings.filterwarnings("ignore")


# ===================== 1. å‘½ä»¤è¡Œå‚æ•°è§£æ =====================
def parse_args():
    parser = argparse.ArgumentParser(description="MLP Classifier with Configurable Hyperparameters")
    # æ ¸å¿ƒè®­ç»ƒå‚æ•°ï¼ˆéœ€é¢‘ç¹è°ƒæ•´çš„å®éªŒå˜é‡ï¼‰
    parser.add_argument("--batch_size", type=int, default=128, help="Batch size for training")
    parser.add_argument("--epochs", type=int, default=160, help="Number of training epochs")
    parser.add_argument("--learning_rate", type=float, default=2e-4, help="Learning rate")
    parser.add_argument("--max_samples_per_class", type=int, default=300, help="Max samples per class after oversampling")
    # å…¶ä»–å¯è°ƒå‚æ•°
    parser.add_argument("--device", type=int, default=5, help="GPU device ID (0-7)")
    parser.add_argument("--dropout", type=float, default=0.3, help="Dropout rate")
    parser.add_argument("--weight_decay", type=float, default=1e-5, help="Weight decay for optimizer")
    parser.add_argument("--oversampling_strategy", type=str, default="smote", choices=["smote", "resample"], 
                        help="Oversampling strategy: 'smote' (åˆæˆé‡‡æ ·) or 'resample' (é‡å¤é‡‡æ ·)")
    return parser.parse_args()


# ===================== 2. åŠ¨æ€é…ç½®ç±»ï¼ˆæ ¹æ®å‘½ä»¤è¡Œå‚æ•°ç”Ÿæˆè·¯å¾„ï¼‰ =====================
class Config:
    def __init__(self, args):
        # ç”Ÿæˆå”¯ä¸€è·¯å¾„åç¼€ï¼ˆåŒ…å«å…³é”®å‚æ•°ï¼Œç”¨äºåŒºåˆ†ä¸åŒå®éªŒï¼‰
        self.param_suffix = f"batch{args.batch_size}_epochs{args.epochs}_lr{args.learning_rate}_maxsamples{args.max_samples_per_class}"
        
        # æ ¸å¿ƒè·¯å¾„ï¼ˆåŠ¨æ€ç”Ÿæˆï¼Œç¡®ä¿ä¸åŒå‚æ•°å®éªŒçš„ç»“æœä¸è¦†ç›–ï¼‰
        self.FEAT_ROOT = "/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/768_npy_charactristic"
        # self.SAVE_MODEL_DIR = f"/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/768_classification_mlp/models_{self.param_suffix}"
        # self.PLOT_DIR = f"/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/768_classification_mlp/plots_{self.param_suffix}"
        self.TB_LOG_DIR = f"/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/768_classification_mlp/tb_logs_{self.param_suffix}"
        self.SAVE_MODEL_DIR = self.TB_LOG_DIR
        self.PLOT_DIR = self.TB_LOG_DIR
        # è®­ç»ƒå‚æ•°ï¼ˆä»å‘½ä»¤è¡Œæ¥æ”¶ï¼‰
        self.BATCH_SIZE = args.batch_size
        self.EPOCHS = args.epochs
        self.LEARNING_RATE = args.learning_rate
        self.WEIGHT_DECAY = args.weight_decay
        self.DROPOUT = args.dropout
        self.DEVICE = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")
        
        # æ•°æ®å¤„ç†å‚æ•°ï¼ˆä»å‘½ä»¤è¡Œæ¥æ”¶ï¼‰
        self.TEST_SIZE = 0.2
        self.RANDOM_STATE = 42
        self.N_SMOTE_NEIGHBORS = 5
        self.OVERSAMPLING_STRATEGY = args.oversampling_strategy
        self.MAX_SAMPLES_PER_CLASS = args.max_samples_per_class
        
        # è¯„ä¼°å‚æ•°
        self.EVAL_METRIC = "weighted"  # è€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡çš„åŠ æƒå¹³å‡
        self.PLOT_CONFUSION_MATRIX = True


# ===================== 3. æ•°æ®åŠ è½½ä¸æ ‡ç­¾å¤„ç† =====================
def parse_class_from_filename(filename):
    """ä»ç‰¹å¾æ–‡ä»¶åè§£æç±»åˆ«ï¼ˆæ ¼å¼ï¼šæ•°æ®é›†å__and__ç±»åˆ«å.npyï¼‰"""
    prefix = filename.replace(".npy", "")
    if "__and__" not in prefix:
        raise ValueError(f"æ–‡ä»¶åæ ¼å¼é”™è¯¯ï¼ˆéœ€ä¸ºã€Œæ•°æ®é›†å__and__ç±»åˆ«å.npyã€ï¼‰ï¼š{filename}")
    dataset_name, class_name = prefix.split("__and__", 1)
    return dataset_name, class_name


def load_all_features_and_labels(feat_root):
    """åŠ è½½æ‰€æœ‰ç‰¹å¾æ–‡ä»¶ï¼Œç”Ÿæˆæ ‡ç­¾æ˜ å°„ï¼ˆæ¯ä¸ªæ–‡ä»¶å¯¹åº”ä¸€ä¸ªç±»åˆ«ï¼‰"""
    print(f"ğŸ“Š ä» {feat_root} åŠ è½½ç‰¹å¾æ–‡ä»¶...")
    
    # ç­›é€‰ç‰¹å¾æ–‡ä»¶ï¼ˆå¿½ç•¥_labels.npyå’Œå«'Healthy/healthy'çš„æ–‡ä»¶ï¼‰
    feat_files = []
    for f in os.listdir(feat_root):
        if f.endswith(".npy") and "_labels.npy" not in f and "Healthy" not in f and "healthy" not in f:
            feat_files.append(f)
    
    if len(feat_files) == 0:
        raise FileNotFoundError(f"âŒ åœ¨ {feat_root} æœªæ‰¾åˆ°æœ‰æ•ˆç‰¹å¾æ–‡ä»¶")
    
    # ç”Ÿæˆç±»åˆ«æ˜ å°„
    all_classes = []
    for f in feat_files:
        dataset_name, class_name = parse_class_from_filename(f)
        all_classes.append(f"{dataset_name}_and_{class_name}")
    unique_classes = sorted(list(set(all_classes)))
    class2id = {cls: idx for idx, cls in enumerate(unique_classes)}
    num_classes = len(unique_classes)
    print(f"âœ… ç”Ÿæˆç±»åˆ«æ˜ å°„ï¼šå…± {num_classes} ä¸ªç±»åˆ«")
    for cls, idx in class2id.items():
        print(f"   - ç±»åˆ«ï¼š{cls} â†’ IDï¼š{idx}")
    
    # åŠ è½½ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆæ¯ä¸ªæ–‡ä»¶çš„æ‰€æœ‰æ ·æœ¬å¯¹åº”åŒä¸€ç±»åˆ«ï¼‰
    all_feats = []
    all_labels = []
    for f in tqdm(feat_files, desc="åŠ è½½ç‰¹å¾æ–‡ä»¶"):
        file_path = os.path.join(feat_root, f)
        dataset_name, class_name = parse_class_from_filename(f)
        class_name = f"{dataset_name}_and_{class_name}"
        current_label = class2id[class_name]
        
        # åŠ è½½ç‰¹å¾ï¼ˆå½¢çŠ¶ï¼š[æ ·æœ¬æ•°, 768]ï¼‰
        feats = np.load(file_path).astype(np.float32)
        if feats.shape[1] != 768:
            raise ValueError(f"âŒ {f} ç‰¹å¾ç»´åº¦é”™è¯¯ï¼ˆéœ€ä¸º768ç»´ï¼‰ï¼Œå®é™…ç»´åº¦ï¼š{feats.shape[1]}")
        
        # æ”¶é›†ç‰¹å¾å’Œæ ‡ç­¾
        all_feats.append(feats)
        all_labels.extend([current_label] * feats.shape[0])  # æ¯ä¸ªæ ·æœ¬å¯¹åº”åŒä¸€ç±»åˆ«
    
    # æ‹¼æ¥ä¸ºå…¨å±€æ•°ç»„
    all_feats = np.concatenate(all_feats, axis=0)  # [æ€»æ ·æœ¬æ•°, 768]
    all_labels = np.array(all_labels, dtype=np.int64)  # [æ€»æ ·æœ¬æ•°]
    
    print(f"\nğŸ“ˆ æ•°æ®åŠ è½½å®Œæˆï¼š")
    print(f"   - æ€»æ ·æœ¬æ•°ï¼š{all_feats.shape[0]}")
    print(f"   - ç‰¹å¾ç»´åº¦ï¼š{all_feats.shape[1]}")
    print(f"   - ç±»åˆ«æ•°ï¼š{num_classes}")
    print(f"   - ç±»åˆ«åˆ†å¸ƒï¼š")
    for cls, idx in class2id.items():
        cnt = np.sum(all_labels == idx)
        print(f"     * {cls}ï¼š{cnt} ä¸ªæ ·æœ¬ï¼ˆ{cnt/all_labels.shape[0]*100:.1f}%ï¼‰")
    
    return all_feats, all_labels, class2id, unique_classes


# ===================== 4. æ•°æ®é¢„å¤„ç†ï¼ˆåˆ’åˆ†+å½’ä¸€åŒ–+è¿‡é‡‡æ ·ï¼‰ =====================
def preprocess_data(all_feats, all_labels, config):
    """ç»å…¸æ•°æ®é¢„å¤„ç†ï¼šåˆ†å±‚åˆ’åˆ†+å½’ä¸€åŒ–+å¤šæ•°ç±»ä¸‹é‡‡æ ·+å°‘æ•°ç±»SMOTEè¿‡é‡‡æ ·"""
    print(f"\nğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
    # 1. åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆä¿è¯ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼‰
    train_feat, test_feat, train_label, test_label = train_test_split(
        all_feats, all_labels,
        test_size=config.TEST_SIZE,
        stratify=all_labels,
        random_state=config.RANDOM_STATE
    )
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†ï¼š{train_feat.shape[0]} æ ·æœ¬")
    print(f"   - æµ‹è¯•é›†ï¼š{test_feat.shape[0]} æ ·æœ¬")
    
    # 2. å½’ä¸€åŒ–ï¼ˆZ-Scoreï¼šåŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼‰
    train_mean = np.mean(train_feat, axis=0)  # æŒ‰ç‰¹å¾ç»´åº¦è®¡ç®—å‡å€¼ [768]
    train_std = np.std(train_feat, axis=0)    # æŒ‰ç‰¹å¾ç»´åº¦è®¡ç®—æ ‡å‡†å·® [768]
    train_std = np.where(train_std < 1e-8, 1e-8, train_std)  # é¿å…é™¤ä»¥0
    
    train_feat_norm = (train_feat - train_mean) / train_std
    test_feat_norm = (test_feat - train_mean) / train_std
    
    print(f"âœ… å½’ä¸€åŒ–å®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{train_feat_norm.min():.4f}, {train_feat_norm.max():.4f}]")
    print(f"   - æµ‹è¯•é›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{test_feat_norm.min():.4f}, {test_feat_norm.max():.4f}]")
    
    # 3. è¿‡é‡‡æ ·ï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·+å°‘æ•°ç±»SMOTEï¼Œæ¯ç±»é™åˆ¶æœ€å¤§æ ·æœ¬æ•°ï¼‰
    print(f"\nâš–ï¸ å¼€å§‹è¿‡é‡‡æ ·ï¼ˆç­–ç•¥ï¼š{config.OVERSAMPLING_STRATEGY}ï¼Œæ¯ç±»æœ€å¤š{config.MAX_SAMPLES_PER_CLASS}æ ·æœ¬ï¼‰...")
    print(f"   - è¿‡é‡‡æ ·å‰è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    unique_labels = np.unique(train_label)
    for label in unique_labels:
        cnt = np.sum(train_label == label)
        print(f"     * ç±»åˆ«{label}ï¼š{cnt} æ ·æœ¬")
    
    # æ­¥éª¤1ï¼šæŒ‰ç±»åˆ«æˆªæ–­ï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·åˆ°max_samplesï¼‰
    from collections import defaultdict
    np.random.seed(config.RANDOM_STATE)  # å…¨å±€éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°
    class_data = defaultdict(list)
    
    # æŒ‰ç±»åˆ«æ”¶é›†è®­ç»ƒé›†æ ·æœ¬
    for feat, label in zip(train_feat_norm, train_label):
        class_data[label].append(feat)
    
    # æˆªæ–­å¤šæ•°ç±»ï¼Œä¿ç•™å°‘æ•°ç±»å…¨éƒ¨æ ·æœ¬
    truncated_data = []
    truncated_labels = []
    for label in class_data:
        samples = np.array(class_data[label])
        n_samples = len(samples)
        
        if n_samples > config.MAX_SAMPLES_PER_CLASS:
            # å¤šæ•°ç±»ï¼šéšæœºä¸‹é‡‡æ ·åˆ°max_samples
            selected_idx = np.random.choice(n_samples, config.MAX_SAMPLES_PER_CLASS, replace=False)
            truncated_samples = samples[selected_idx]
        else:
            # å°‘æ•°ç±»ï¼šä¿ç•™å…¨éƒ¨æ ·æœ¬
            truncated_samples = samples
        
        truncated_data.append(truncated_samples)
        truncated_labels.append(np.full(len(truncated_samples), label))
    
    # æ‹¼æ¥æˆªæ–­åçš„æ•°æ®
    truncated_data = np.concatenate(truncated_data, axis=0)
    truncated_labels = np.concatenate(truncated_labels, axis=0)
    
    # æ­¥éª¤2ï¼šSMOTEè¿‡é‡‡æ ·ï¼ˆè¡¥å…¨åˆ°max_samplesï¼‰
    if len(unique_labels) == 1:
        print(f"âš ï¸ ä»…1ä¸ªç±»åˆ«ï¼Œæ— éœ€SMOTEï¼Œä½¿ç”¨æˆªæ–­åæ•°æ®")
        train_feat_smote = truncated_data
        train_label_smote = truncated_labels
    else:
        from imblearn.over_sampling import SMOTE
        # å®šä¹‰æ¯ç±»éœ€è¦ç”Ÿæˆçš„æ ·æœ¬æ•°ï¼ˆè¡¥åˆ°max_samplesï¼‰
        sampling_strategy = {label: config.MAX_SAMPLES_PER_CLASS for label in unique_labels}
        smote = SMOTE(
            sampling_strategy=sampling_strategy,
            k_neighbors=min(5, min(np.bincount(truncated_labels)) - 1),  # å®‰å…¨è¿‘é‚»æ•°ï¼ˆé¿å…æ ·æœ¬æ•°ä¸è¶³ï¼‰
            random_state=config.RANDOM_STATE
        )
        train_feat_smote, train_label_smote = smote.fit_resample(truncated_data, truncated_labels)
    
    # è¾“å‡ºè¿‡é‡‡æ ·ç»“æœ
    print(f"   - è¿‡é‡‡æ ·åè®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    for label in np.unique(train_label_smote):
        cnt = np.sum(train_label_smote == label)
        print(f"     * ç±»åˆ«{label}ï¼š{cnt} æ ·æœ¬")
    print(f"   - è¿‡é‡‡æ ·åæ€»æ ·æœ¬æ•°ï¼š{train_feat_smote.shape[0]}")
    
    return (
        train_feat_smote, train_label_smote,  # è¿‡é‡‡æ ·åçš„è®­ç»ƒé›†
        test_feat_norm, test_label,           # å½’ä¸€åŒ–åçš„æµ‹è¯•é›†
        train_mean, train_std                 # å½’ä¸€åŒ–ç»Ÿè®¡é‡ï¼ˆåç»­æ¨ç†ç”¨ï¼‰
    )


# ===================== 5. æ•°æ®é›†ä¸DataLoaderå®šä¹‰ =====================
class MLPFeatDataset(Dataset):
    """ç‰¹å¾æ•°æ®é›†ï¼šé€‚é…PyTorch DataLoader"""
    def __init__(self, feats, labels):
        self.feats = torch.tensor(feats, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)
        assert len(self.feats) == len(self.labels), "ç‰¹å¾ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…ï¼"
    
    def __len__(self):
        return len(self.feats)
    
    def __getitem__(self, idx):
        return {"feat": self.feats[idx], "label": self.labels[idx]}


def create_dataloaders(train_feat, train_label, test_feat, test_label, config):
    """åˆ›å»ºè®­ç»ƒé›†/æµ‹è¯•é›†DataLoaderï¼ˆè®­ç»ƒé›†æ‰“ä¹±ï¼Œæµ‹è¯•é›†ä¸æ‰“ä¹±ï¼‰"""
    train_dataset = MLPFeatDataset(train_feat, train_label)
    test_dataset = MLPFeatDataset(test_feat, test_label)
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=True,   # è®­ç»ƒé›†æ‰“ä¹±ï¼Œå¢å¼ºæ³›åŒ–æ€§
        drop_last=True, # ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´æ‰¹æ¬¡
        pin_memory=True # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,  # æµ‹è¯•é›†ä¸æ‰“ä¹±ï¼Œä¾¿äºç»“æœå¤ç°
        pin_memory=True
    )
    
    print(f"\nğŸš€ DataLoaderåˆ›å»ºå®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†æ‰¹æ¬¡ï¼š{len(train_loader)} æ‰¹ï¼ˆæ¯æ‰¹{config.BATCH_SIZE}æ ·æœ¬ï¼‰")
    print(f"   - æµ‹è¯•é›†æ‰¹æ¬¡ï¼š{len(test_loader)} æ‰¹ï¼ˆæ¯æ‰¹{config.BATCH_SIZE}æ ·æœ¬ï¼‰")
    
    return train_loader, test_loader


# ===================== 6. MLPåˆ†ç±»æ¨¡å‹å®šä¹‰ï¼ˆé€‚é…768ç»´è¾“å…¥ï¼‰ =====================
class MLPClassifier(nn.Module):
    """è½»é‡çº§MLPåˆ†ç±»å™¨ï¼šè¾“å…¥768ç»´ç‰¹å¾ï¼Œè¾“å‡ºç±»åˆ«æ¦‚ç‡"""
    def __init__(self, input_dim=768, num_classes=2, dropout=0.3):
        super().__init__()
        self.classifier = nn.Sequential(
            # ç¬¬ä¸€å±‚ï¼š768 â†’ 512ï¼ŒReLUæ¿€æ´» + Dropout
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            # ç¬¬äºŒå±‚ï¼š512 â†’ 256ï¼ŒReLUæ¿€æ´» + Dropout
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            # è¾“å‡ºå±‚ï¼š256 â†’ ç±»åˆ«æ•°ï¼ˆæ— æ¿€æ´»ï¼ŒCrossEntropyLossè‡ªå¸¦Softmaxï¼‰
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼šx â†’ [batch_size, 768] â†’ logits â†’ [batch_size, num_classes]"""
        return self.classifier(x)


# ===================== 7. è®­ç»ƒä¸è¯„ä¼°å‡½æ•° =====================
def train_one_epoch(model, dataloader, criterion, optimizer, scaler, config):
    """è®­ç»ƒä¸€è½®ï¼Œè¿”å›è®­ç»ƒé›†å…¨æŒ‡æ ‡ï¼ˆæŸå¤±+å‡†ç¡®ç‡+ç²¾ç¡®ç‡+å¬å›ç‡+F1ï¼‰"""
    model.train()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    
    for batch in tqdm(dataloader, desc="è®­ç»ƒä¸­"):
        # æ•°æ®ç§»è‡³GPU
        feats = batch["feat"].to(config.DEVICE)
        labels = batch["label"].to(config.DEVICE)
        
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        
        # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜+åŠ é€Ÿï¼‰
        with autocast():
            logits = model(feats)
            loss = criterion(logits, labels)
        
        # åå‘ä¼ æ’­ä¸ä¼˜åŒ–
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        # è®°å½•æŸå¤±å’Œé¢„æµ‹ç»“æœ
        total_loss += loss.item() * feats.size(0)
        preds = torch.argmax(logits, dim=1).cpu().numpy()  # å–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«
        all_preds.extend(preds)
        all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—è®­ç»ƒé›†æŒ‡æ ‡
    avg_loss = total_loss / len(dataloader.dataset)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    recall = recall_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    f1 = f1_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    
    return avg_loss, accuracy, precision, recall, f1


def evaluate_model(model, dataloader, criterion, class2id, config, is_test=False):
    """è¯„ä¼°æ¨¡å‹ï¼Œè¿”å›å…¨æŒ‡æ ‡ï¼ˆæŸå¤±+å‡†ç¡®ç‡+ç²¾ç¡®ç‡+å¬å›ç‡+F1ï¼‰ï¼Œæµ‹è¯•é›†è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
    model.eval()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():  # å…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœæ˜¾å­˜
        for batch in tqdm(dataloader, desc="è¯„ä¼°ä¸­"):
            feats = batch["feat"].to(config.DEVICE)
            labels = batch["label"].to(config.DEVICE)
            
            with autocast():
                logits = model(feats)
                loss = criterion(logits, labels)
            
            # è®°å½•ç»“æœ
            total_loss += loss.item() * feats.size(0)
            preds = torch.argmax(logits, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    avg_loss = total_loss / len(dataloader.dataset)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    recall = recall_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    f1 = f1_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    
    # æµ‹è¯•é›†é¢å¤–è¾“å‡ºï¼šè¯¦ç»†ç±»åˆ«æŒ‡æ ‡+æ··æ·†çŸ©é˜µ
    if is_test:
        print(f"\n========== æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°ç»“æœ ==========")
        print(f"1. æ€»ä½“æŒ‡æ ‡ï¼ˆ{config.EVAL_METRIC}å¹³å‡ï¼‰ï¼š")
        print(f"   - æŸå¤±ï¼š{avg_loss:.4f}")
        print(f"   - å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š{accuracy:.4f}")
        print(f"   - ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼š{precision:.4f}")
        print(f"   - å¬å›ç‡ï¼ˆRecallï¼‰ï¼š{recall:.4f}")
        print(f"   - F1åˆ†æ•°ï¼š{f1:.4f}\n")
        
        # è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡
        id2class = {idx: cls for cls, idx in class2id.items()}  # IDâ†’ç±»åˆ«åæ˜ å°„
        class_precision = precision_score(all_labels, all_preds, average=None, zero_division=0)
        class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)
        class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)
        
        print(f"2. å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡ï¼š")
        for idx in np.unique(all_labels):
            cls_name = id2class[idx]
            print(f"   - {cls_name}ï¼ˆID:{idx}ï¼‰ï¼š")
            print(f"     ç²¾ç¡®ç‡ï¼š{class_precision[idx]:.4f} | å¬å›ç‡ï¼š{class_recall[idx]:.4f} | F1ï¼š{class_f1[idx]:.4f}")
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆè‹¥å¼€å¯ï¼‰
        if config.PLOT_CONFUSION_MATRIX:
            cm = confusion_matrix(all_labels, all_preds)
            plt.figure(figsize=(12 + len(class2id)//5, 10 + len(class2id)//5))  # ç±»åˆ«å¤šåˆ™è°ƒå¤§å°ºå¯¸
            sns.heatmap(
                cm, 
                annot=True, 
                fmt="d", 
                cmap="Blues",
                xticklabels=[id2class[idx] for idx in range(len(class2id))],
                yticklabels=[id2class[idx] for idx in range(len(class2id))],
                annot_kws={"fontsize": 8 if len(class2id) <= 10 else 6}  # ç±»åˆ«å¤šåˆ™è°ƒå°å­—ä½“
            )
            plt.xlabel("é¢„æµ‹ç±»åˆ«", fontsize=12)
            plt.ylabel("çœŸå®ç±»åˆ«", fontsize=12)
            plt.title("æµ‹è¯•é›†æ··æ·†çŸ©é˜µ", fontsize=14)
            plt.xticks(rotation=45 if len(class2id) <= 15 else 90, ha="right")  # ç±»åˆ«åè¿‡é•¿åˆ™æ—‹è½¬
            plt.tight_layout()
            cm_save_path = os.path.join(config.PLOT_DIR, "test_confusion_matrix.png")
            plt.savefig(cm_save_path, dpi=300, bbox_inches="tight")
            plt.close()
            print(f"\n3. æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³ï¼š{cm_save_path}")
    
    return avg_loss, accuracy, precision, recall, f1


# ===================== 8. è®­ç»ƒæ—¥å¿—ä¿å­˜ï¼ˆCSVæ ¼å¼ï¼Œç”¨äºç¦»çº¿åˆ†æï¼‰ =====================
def save_training_logs(logs, save_dir):
    """å°†æ¯è½®è®­ç»ƒçš„æŒ‡æ ‡ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
    # è½¬æ¢ä¸ºDataFrameï¼Œåˆ—åæ¸…æ™°
    log_df = pd.DataFrame(logs, columns=[
        "epoch", 
        "train_loss", "train_accuracy", "train_precision", "train_recall", "train_f1",
        "test_loss", "test_accuracy", "test_precision", "test_recall", "test_f1"
    ])
    # ä¿å­˜è·¯å¾„
    csv_path = os.path.join(save_dir, "mlp_training_logs.csv")
    log_df.to_csv(csv_path, index=False, encoding="utf-8")
    print(f"\nğŸ“„ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜è‡³ï¼š{csv_path}")
    return csv_path


# ===================== 9. ä¸»å‡½æ•°ï¼ˆä¸²è”å…¨æµç¨‹ï¼Œé›†æˆTensorBoardï¼‰ =====================
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    # ç”ŸæˆåŠ¨æ€é…ç½®ï¼ˆå«å”¯ä¸€è·¯å¾„ï¼‰
    config = Config(args)
    
    # åˆ›å»ºå¿…è¦ç›®å½•ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
    os.makedirs(config.SAVE_MODEL_DIR, exist_ok=True)
    os.makedirs(config.PLOT_DIR, exist_ok=True)
    os.makedirs(config.TB_LOG_DIR, exist_ok=True)
    
    # Step 1ï¼šåŠ è½½ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆæŒ‰æ–‡ä»¶åè§£æç±»åˆ«ï¼‰
    all_feats, all_labels, class2id, unique_classes = load_all_features_and_labels(config.FEAT_ROOT)
    num_classes = len(class2id)
    
    # Step 2ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆåˆ’åˆ†+å½’ä¸€åŒ–+è¿‡é‡‡æ ·ï¼‰
    (train_feat_smote, train_label_smote, 
     test_feat_norm, test_label, 
     train_mean, train_std) = preprocess_data(all_feats, all_labels, config)
    
    # Step 3ï¼šåˆ›å»ºDataLoader
    train_loader, test_loader = create_dataloaders(
        train_feat_smote, train_label_smote,
        test_feat_norm, test_label,
        config
    )
    
    # Step 4ï¼šåˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = MLPClassifier(
        input_dim=768,
        num_classes=num_classes,
        dropout=config.DROPOUT
    ).to(config.DEVICE)
    print(f"\nğŸ“Œ MLPæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆè®¾å¤‡ï¼š{config.DEVICE}ï¼‰")
    print(f"   - è¾“å…¥ç»´åº¦ï¼š768")
    print(f"   - è¾“å‡ºç»´åº¦ï¼š{num_classes}ï¼ˆç±»åˆ«æ•°ï¼‰")
    
    # æŸå¤±å‡½æ•°ï¼ˆäº¤å‰ç†µï¼šé€‚é…å¤šåˆ†ç±»ï¼‰
    criterion = nn.CrossEntropyLoss()
    # ä¼˜åŒ–å™¨ï¼ˆAdamWï¼šå¸¦æƒé‡è¡°å‡ï¼Œé˜²è¿‡æ‹Ÿåˆï¼‰
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.LEARNING_RATE,
        weight_decay=config.WEIGHT_DECAY
    )
    # æ··åˆç²¾åº¦è®­ç»ƒå™¨ï¼ˆèŠ‚çœæ˜¾å­˜+åŠ é€Ÿï¼‰
    scaler = GradScaler()
    
    # åˆå§‹åŒ–TensorBoardï¼ˆå®æ—¶å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼‰
    tb_writer = SummaryWriter(log_dir=config.TB_LOG_DIR)
    train_logs = []  # ä¿ç•™CSVæ—¥å¿—ï¼Œç”¨äºç¦»çº¿åˆ†æ
    best_test_f1 = 0.0  # è·Ÿè¸ªæœ€ä¼˜æ¨¡å‹çš„æµ‹è¯•é›†F1åˆ†æ•°
    
    # Step 5ï¼šè®­ç»ƒå¾ªç¯ï¼ˆè·Ÿè¸ªéªŒè¯é›†F1ï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼‰
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼ˆå…±{config.EPOCHS}è½®ï¼‰")
    for epoch in range(1, config.EPOCHS + 1):
        print(f"\n===== Epoch {epoch}/{config.EPOCHS} =====")
        
        # è®­ç»ƒä¸€è½®ï¼Œè·å–è®­ç»ƒé›†å…¨æŒ‡æ ‡
        train_loss, train_acc, train_prec, train_rec, train_f1 = train_one_epoch(
            model, train_loader, criterion, optimizer, scaler, config
        )
        
        # è¯„ä¼°æµ‹è¯•é›†ï¼Œè·å–æµ‹è¯•é›†å…¨æŒ‡æ ‡ï¼ˆéæœ€ç»ˆæµ‹è¯•ï¼Œä¸è¾“å‡ºè¯¦ç»†æŒ‡æ ‡ï¼‰
        test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate_model(
            model, test_loader, criterion, class2id, config, is_test=False
        )
        
        # 1. æ‰“å°æ¯è½®æ—¥å¿—
        print(f"ğŸ“Š è®­ç»ƒé›†ï¼š")
        print(f"   æŸå¤±ï¼š{train_loss:.4f} | å‡†ç¡®ç‡ï¼š{train_acc:.4f} | ç²¾ç¡®ç‡ï¼š{train_prec:.4f} | å¬å›ç‡ï¼š{train_rec:.4f} | F1ï¼š{train_f1:.4f}")
        print(f"ğŸ“Š æµ‹è¯•é›†ï¼š")
        print(f"   æŸå¤±ï¼š{test_loss:.4f} | å‡†ç¡®ç‡ï¼š{test_acc:.4f} | ç²¾ç¡®ç‡ï¼š{test_prec:.4f} | å¬å›ç‡ï¼š{test_rec:.4f} | F1ï¼š{test_f1:.4f}")
        
        # 2. è®°å½•åˆ°TensorBoardï¼ˆå®æ—¶å¯è§†åŒ–ï¼‰
        tb_writer.add_scalar("Loss/train", train_loss, epoch)
        tb_writer.add_scalar("Accuracy/train", train_acc, epoch)
        tb_writer.add_scalar("Precision/train", train_prec, epoch)
        tb_writer.add_scalar("Recall/train", train_rec, epoch)
        tb_writer.add_scalar("F1/train", train_f1, epoch)
        
        tb_writer.add_scalar("Loss/test", test_loss, epoch)
        tb_writer.add_scalar("Accuracy/test", test_acc, epoch)
        tb_writer.add_scalar("Precision/test", test_prec, epoch)
        tb_writer.add_scalar("Recall/test", test_rec, epoch)
        tb_writer.add_scalar("F1/test", test_f1, epoch)
        
        # 3. ä¿ç•™CSVæ—¥å¿—ï¼ˆç¦»çº¿åˆ†æç”¨ï¼‰
        train_logs.append({
            "epoch": epoch,
            "train_loss": train_loss, "train_accuracy": train_acc, 
            "train_precision": train_prec, "train_recall": train_rec, "train_f1": train_f1,
            "test_loss": test_loss, "test_accuracy": test_acc,
            "test_precision": test_prec, "test_recall": test_rec, "test_f1": test_f1
        })
        
        # 4. ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆåŸºäºæµ‹è¯•é›†F1ï¼‰
        if test_f1 > best_test_f1:
            best_test_f1 = test_f1
            save_path = os.path.join(config.SAVE_MODEL_DIR, "best_model.pth")
            torch.save({
                "model_state_dict": model.state_dict(),
                "class2id": class2id,
                "train_mean": train_mean,
                "train_std": train_std
            }, save_path)
            print(f"âœ… ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆæµ‹è¯•é›†F1ï¼š{best_test_f1:.4f}ï¼‰è‡³ {save_path}")
    
    # å…³é—­TensorBoardå†™å…¥å™¨
    tb_writer.close()
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—ä¸ºCSVï¼ˆç¦»çº¿åˆ†æç”¨ï¼‰
    save_training_logs(train_logs, config.PLOT_DIR)
    
    # Step 6ï¼šåŠ è½½æœ€ä¼˜æ¨¡å‹ï¼Œè¿›è¡Œæœ€ç»ˆæµ‹è¯•ï¼ˆè¾“å‡ºè¯¦ç»†ç±»åˆ«æŒ‡æ ‡ï¼‰
    print(f"\n========== åŠ è½½æœ€ä¼˜æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯• ==========")
    checkpoint = torch.load(os.path.join(config.SAVE_MODEL_DIR, "best_model.pth"))
    best_model = MLPClassifier(input_dim=768, num_classes=num_classes).to(config.DEVICE)
    best_model.load_state_dict(checkpoint["model_state_dict"])
    
    # æœ€ç»ˆæµ‹è¯•ï¼ˆè¾“å‡ºè¯¦ç»†ç±»åˆ«æŒ‡æ ‡å’Œæ··æ·†çŸ©é˜µï¼‰
    evaluate_model(best_model, test_loader, criterion, class2id, config, is_test=True)
    
    print(f"\nğŸ‰ MLPå¤šç±»åˆ«åˆ†ç±»ä»»åŠ¡å®Œæˆï¼")
    print(f"   - æœ€ä¼˜æ¨¡å‹è·¯å¾„ï¼š{config.SAVE_MODEL_DIR}/best_model.pth")
    print(f"   - è®­ç»ƒæ—¥å¿—è·¯å¾„ï¼š{os.path.join(config.PLOT_DIR, 'mlp_training_logs.csv')}")
    print(f"   - TensorBoardæ—¥å¿—ç›®å½•ï¼š{config.TB_LOG_DIR}ï¼ˆå¯é€šè¿‡å‘½ä»¤ `tensorboard --logdir={config.TB_LOG_DIR}` å¯åŠ¨æŸ¥çœ‹ï¼‰")
    if config.PLOT_CONFUSION_MATRIX:
        print(f"   - æ··æ·†çŸ©é˜µè·¯å¾„ï¼š{os.path.join(config.PLOT_DIR, 'test_confusion_matrix.png')}")


if __name__ == "__main__":
    main()