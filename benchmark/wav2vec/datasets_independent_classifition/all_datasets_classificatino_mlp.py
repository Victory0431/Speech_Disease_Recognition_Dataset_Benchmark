import os
import numpy as np
import torch
import torch.nn as nn
import pandas as pd
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
from torch.utils.tensorboard import SummaryWriter
import argparse

warnings.filterwarnings("ignore")


# ===================== 1. å‘½ä»¤è¡Œå‚æ•°è§£æï¼ˆæ ¸å¿ƒæ–°å¢ï¼šæ•°æ®é›†ç›®å½•å‚æ•°ï¼‰ =====================
def parse_args():
    parser = argparse.ArgumentParser(description="MLP Classifier for Wav2Vec2 Features (Dataset-Specific)")
    # æ–°å¢ï¼šæ•°æ®é›†ç›®å½•ï¼ˆè¾“å…¥å‚æ•°ï¼Œå¦‚/mnt/data/.../Asthma_Detection_Tawfikï¼‰
    parser.add_argument("--dataset_dir", type=str, required=True, 
                        help="Path to dataset directory (contains class subfolders, e.g., /mnt/.../Asthma_Detection_Tawfik)")
    # æ ¸å¿ƒè®­ç»ƒå‚æ•°
    parser.add_argument("--batch_size", type=int, default=128, help="Batch size for training")
    parser.add_argument("--epochs", type=int, default=160, help="Number of training epochs")
    parser.add_argument("--learning_rate", type=float, default=2e-4, help="Learning rate (AdamW)")
    parser.add_argument("--max_samples_per_class", type=int, default=300, help="Max samples per class after oversampling")
    # å…¶ä»–å¯è°ƒå‚æ•°
    parser.add_argument("--device", type=int, default=5, help="GPU device ID (0-7)")
    parser.add_argument("--dropout", type=float, default=0.3, help="Dropout rate in MLP")
    parser.add_argument("--weight_decay", type=float, default=1e-5, help="Weight decay for AdamW")
    parser.add_argument("--oversampling_strategy", type=str, default="smote", choices=["smote", "resample"], 
                        help="Oversampling strategy: 'smote' (synthetic) or 'resample' (replication)")
    # å›ºå®šè·¯å¾„å‚æ•°ï¼ˆæ— éœ€é¢‘ç¹ä¿®æ”¹ï¼‰
    parser.add_argument("--feat_root", type=str, 
                        default="/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/768_npy_charactristic",
                        help="Root directory of Wav2Vec2 768D features (.npy files)")
    parser.add_argument("--result_csv", type=str, 
                        default="/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/datasets_independent_classifition/all_datasets_results_wav2vec_mlp.csv",
                        help="Fixed CSV file to append dataset results")
    parser.add_argument("--tb_root", type=str, 
                        default="/mnt/data/test1/Speech_Disease_Recognition_Dataset_Benchmark/benchmark/wav2vec/datasets_independent_classifition/results",
                        help="Root directory for TensorBoard logs")
    return parser.parse_args()


# ===================== 2. åŠ¨æ€é…ç½®ç±»ï¼ˆåŸºäºè¾“å…¥å‚æ•°ç”Ÿæˆè·¯å¾„ï¼‰ =====================
class Config:
    def __init__(self, args):
        # ä»è¾“å…¥æ•°æ®é›†ç›®å½•æå–å…³é”®ä¿¡æ¯
        self.dataset_name = os.path.basename(args.dataset_dir.strip(os.sep))  # æ•°æ®é›†åï¼ˆå¦‚Asthma_Detection_Tawfikï¼‰
        self.class_subdirs = [d for d in os.listdir(args.dataset_dir) if os.path.isdir(os.path.join(args.dataset_dir, d))]
        if not self.class_subdirs:
            raise ValueError(f"No class subfolders found in dataset directory: {args.dataset_dir}")
        
        # æ ¸å¿ƒè·¯å¾„ï¼ˆåŠ¨æ€ç”Ÿæˆï¼Œé¿å…è¦†ç›–ï¼‰
        self.FEAT_ROOT = args.feat_root  # Wav2Vec2ç‰¹å¾æ ¹ç›®å½•
        self.RESULT_CSV = args.result_csv  # å›ºå®šç»“æœCSVè·¯å¾„
        # TensorBoardæ—¥å¿—ç›®å½•ï¼ˆæ•°æ®é›†å+å‚æ•°æ ‡è¯†ï¼‰
        self.param_suffix = f"batch{args.batch_size}_lr{args.learning_rate}_maxsamples{args.max_samples_per_class}"
        self.TB_LOG_DIR = os.path.join(args.tb_root, f"{self.dataset_name}_log")
        self.SAVE_MODEL_DIR = self.TB_LOG_DIR  # æœ€ä¼˜æ¨¡å‹ä¿å­˜åœ¨TBç›®å½•ä¸‹
        self.PLOT_DIR = self.TB_LOG_DIR        # æ··æ·†çŸ©é˜µä¿å­˜åœ¨TBç›®å½•ä¸‹
        
        # è®­ç»ƒå‚æ•°
        self.BATCH_SIZE = args.batch_size
        self.EPOCHS = args.epochs
        self.LEARNING_RATE = args.learning_rate
        self.WEIGHT_DECAY = args.weight_decay
        self.DROPOUT = args.dropout
        self.DEVICE = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")
        
        # æ•°æ®å¤„ç†å‚æ•°ï¼ˆ7:1.5:1.5åˆ’åˆ†ï¼‰
        self.TRAIN_SIZE = 0.7
        self.VAL_TEST_SIZE = 0.3  # éªŒè¯é›†+æµ‹è¯•é›†å æ¯”
        self.VAL_SIZE = 0.5       # éªŒè¯é›†å éªŒè¯é›†+æµ‹è¯•é›†çš„50%ï¼ˆå³æ€»æ•°æ®çš„15%ï¼‰
        self.RANDOM_STATE = 42
        self.N_SMOTE_NEIGHBORS = 5
        self.OVERSAMPLING_STRATEGY = args.oversampling_strategy
        self.MAX_SAMPLES_PER_CLASS = args.max_samples_per_class
        
        # è¯„ä¼°å‚æ•°
        self.EVAL_METRIC = "weighted"  # é€‚é…ç±»åˆ«ä¸å¹³è¡¡
        self.PLOT_CONFUSION_MATRIX = True


# ===================== 3. æ•°æ®åŠ è½½ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šæŒ‰æ•°æ®é›†ç›®å½•è§£æç±»åˆ«+åŒ¹é…ç‰¹å¾æ–‡ä»¶ï¼‰ =====================
def load_dataset_features(config):
    """
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. ä»æ•°æ®é›†ç›®å½•çš„ç±»å­æ–‡ä»¶å¤¹è·å–ç±»åˆ«å
    2. æŒ‰ã€Œæ•°æ®é›†å__and__ç±»åˆ«å.npyã€æ ¼å¼åŒ¹é…ç‰¹å¾æ–‡ä»¶
    3. åŠ è½½ç‰¹å¾ä¸æ ‡ç­¾ï¼ˆæ¯ä¸ªç‰¹å¾æ–‡ä»¶å¯¹åº”ä¸€ä¸ªç±»åˆ«ï¼‰
    """
    print(f"\nğŸ“Š å¼€å§‹åŠ è½½ {config.dataset_name} æ•°æ®é›†çš„ç‰¹å¾...")
    print(f"   - æ•°æ®é›†ç±»åˆ«æ•°ï¼š{len(config.class_subdirs)}")
    print(f"   - ç±»åˆ«åˆ—è¡¨ï¼š{config.class_subdirs}")
    print(f"   - ç‰¹å¾æ–‡ä»¶åŒ¹é…æ ¼å¼ï¼š{config.dataset_name}__and__[ç±»åˆ«å].npy")
    
    # ç”Ÿæˆç±»åˆ«æ˜ å°„ï¼ˆIDä»0å¼€å§‹ï¼‰
    class2id = {cls: idx for idx, cls in enumerate(sorted(config.class_subdirs))}
    num_classes = len(class2id)
    
    # åŠ è½½ç‰¹å¾ä¸æ ‡ç­¾
    all_feats = []
    all_labels = []
    missing_files = []
    
    for cls_name, cls_id in class2id.items():
        # æ„é€ ç‰¹å¾æ–‡ä»¶åï¼ˆå…³é”®æ ¼å¼ï¼šæ•°æ®é›†å__and__ç±»åˆ«å.npyï¼‰
        feat_filename = f"{config.dataset_name}__and__{cls_name}.npy"
        feat_path = os.path.join(config.FEAT_ROOT, feat_filename)
        
        # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(feat_path):
            missing_files.append(feat_filename)
            continue
        
        # åŠ è½½768ç»´ç‰¹å¾
        feats = np.load(feat_path).astype(np.float32)
        # éªŒè¯ç‰¹å¾ç»´åº¦
        if feats.shape[1] != 768:
            raise ValueError(f"âŒ ç‰¹å¾æ–‡ä»¶ {feat_filename} ç»´åº¦é”™è¯¯ï¼ˆéœ€768ç»´ï¼‰ï¼Œå®é™…ï¼š{feats.shape[1]}")
        
        # æ”¶é›†ç‰¹å¾ä¸æ ‡ç­¾ï¼ˆè¯¥æ–‡ä»¶æ‰€æœ‰æ ·æœ¬å¯¹åº”åŒä¸€ç±»åˆ«ï¼‰
        all_feats.append(feats)
        all_labels.extend([cls_id] * feats.shape[0])
        print(f"   - {feat_filename}ï¼š{feats.shape[0]} æ ·æœ¬")
    
    # æ£€æŸ¥ç¼ºå¤±æ–‡ä»¶
    if missing_files:
        raise FileNotFoundError(f"âŒ ä»¥ä¸‹ç‰¹å¾æ–‡ä»¶æœªæ‰¾åˆ°ï¼ˆè·¯å¾„ï¼š{config.FEAT_ROOT}ï¼‰ï¼š\n{missing_files}")
    if len(all_feats) == 0:
        raise ValueError(f"âŒ æœªåŠ è½½åˆ°ä»»ä½•ç‰¹å¾æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç‰¹å¾è·¯å¾„ä¸æ–‡ä»¶åæ ¼å¼")
    
    # æ‹¼æ¥ä¸ºå…¨å±€æ•°ç»„
    all_feats = np.concatenate(all_feats, axis=0)  # [æ€»æ ·æœ¬æ•°, 768]
    all_labels = np.array(all_labels, dtype=np.int64)  # [æ€»æ ·æœ¬æ•°]
    
    # è¾“å‡ºåŠ è½½ç»“æœ
    print(f"\nâœ… ç‰¹å¾åŠ è½½å®Œæˆï¼š")
    print(f"   - æ€»æ ·æœ¬æ•°ï¼š{all_feats.shape[0]}")
    print(f"   - ç‰¹å¾ç»´åº¦ï¼š{all_feats.shape[1]}")
    print(f"   - ç±»åˆ«åˆ†å¸ƒï¼š")
    for cls_name, cls_id in class2id.items():
        cnt = np.sum(all_labels == cls_id)
        print(f"     * {cls_name}ï¼ˆID:{cls_id}ï¼‰ï¼š{cnt} æ ·æœ¬ï¼ˆ{cnt/all_labels.shape[0]*100:.1f}%ï¼‰")
    
    return all_feats, all_labels, class2id


# ===================== 4. æ•°æ®é¢„å¤„ç†ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼š7:1.5:1.5åˆ’åˆ†+è¿‡é‡‡æ ·ï¼‰ =====================
def preprocess_data(all_feats, all_labels, config):
    """
    é¢„å¤„ç†æµç¨‹ï¼š
    1. åˆ†å±‚åˆ’åˆ†ï¼šè®­ç»ƒé›†(70%) â†’ éªŒè¯é›†(15%)+æµ‹è¯•é›†(15%)ï¼ˆä¿è¯ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼‰
    2. å½’ä¸€åŒ–ï¼šåŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
    3. è¿‡é‡‡æ ·ï¼šä»…å¯¹è®­ç»ƒé›†è¿›è¡Œï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·+å°‘æ•°ç±»è¿‡é‡‡æ ·ï¼‰
    """
    print(f"\nğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
    # Step 1ï¼š7:1.5:1.5 åˆ†å±‚åˆ’åˆ†
    # ç¬¬ä¸€æ¬¡åˆ’åˆ†ï¼šè®­ç»ƒé›†(70%) + ä¸´æ—¶é›†(30%ï¼Œç”¨äºåç»­åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†)
    train_feat, temp_feat, train_label, temp_label = train_test_split(
        all_feats, all_labels,
        train_size=config.TRAIN_SIZE,
        stratify=all_labels,
        random_state=config.RANDOM_STATE
    )
    # ç¬¬äºŒæ¬¡åˆ’åˆ†ï¼šä¸´æ—¶é›† â†’ éªŒè¯é›†(15%) + æµ‹è¯•é›†(15%)
    val_feat, test_feat, val_label, test_label = train_test_split(
        temp_feat, temp_label,
        train_size=config.VAL_SIZE,
        stratify=temp_label,
        random_state=config.RANDOM_STATE
    )
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼ˆ7:1.5:1.5ï¼‰ï¼š")
    print(f"   - è®­ç»ƒé›†ï¼š{train_feat.shape[0]} æ ·æœ¬")
    print(f"   - éªŒè¯é›†ï¼š{val_feat.shape[0]} æ ·æœ¬")
    print(f"   - æµ‹è¯•é›†ï¼š{test_feat.shape[0]} æ ·æœ¬")
    
    # Step 2ï¼šZ-Scoreå½’ä¸€åŒ–ï¼ˆåŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡ï¼‰
    train_mean = np.mean(train_feat, axis=0)  # [768]
    train_std = np.std(train_feat, axis=0)    # [768]
    # é¿å…æ ‡å‡†å·®ä¸º0å¯¼è‡´é™¤ä»¥0
    train_std = np.where(train_std < 1e-8, 1e-8, train_std)
    
    # å½’ä¸€åŒ–æ‰€æœ‰é›†ï¼ˆéªŒè¯é›†/æµ‹è¯•é›†ç”¨è®­ç»ƒé›†ç»Ÿè®¡é‡ï¼‰
    train_feat_norm = (train_feat - train_mean) / train_std
    val_feat_norm = (val_feat - train_mean) / train_std
    test_feat_norm = (test_feat - train_mean) / train_std
    
    print(f"âœ… å½’ä¸€åŒ–å®Œæˆï¼ˆåŸºäºè®­ç»ƒé›†ç»Ÿè®¡é‡ï¼‰ï¼š")
    print(f"   - è®­ç»ƒé›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{train_feat_norm.min():.4f}, {train_feat_norm.max():.4f}]")
    print(f"   - éªŒè¯é›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{val_feat_norm.min():.4f}, {val_feat_norm.max():.4f}]")
    print(f"   - æµ‹è¯•é›†å½’ä¸€åŒ–åèŒƒå›´ï¼š[{test_feat_norm.min():.4f}, {test_feat_norm.max():.4f}]")
    
    # Step 3ï¼šè®­ç»ƒé›†è¿‡é‡‡æ ·ï¼ˆå¤šæ•°ç±»ä¸‹é‡‡æ ·+å°‘æ•°ç±»è¿‡é‡‡æ ·ï¼‰
    print(f"\nâš–ï¸ å¼€å§‹è®­ç»ƒé›†è¿‡é‡‡æ ·ï¼ˆç­–ç•¥ï¼š{config.OVERSAMPLING_STRATEGY}ï¼Œæœ€å¤§æ ·æœ¬æ•°é˜ˆå€¼{config.MAX_SAMPLES_PER_CLASS}ï¼‰")
    print(f"   - è¿‡é‡‡æ ·å‰è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
    class_counts = {}
    for cls_id in np.unique(train_label):
        cnt = np.sum(train_label == cls_id)
        class_counts[cls_id] = cnt
        print(f"     * ç±»åˆ«{cls_id}ï¼š{cnt} æ ·æœ¬")

    # åˆ¤æ–­æ˜¯å¦æ‰€æœ‰ç±»åˆ«æ ·æœ¬æ•°éƒ½å°äºæœ€å¤§æ ·æœ¬æ•°ï¼ˆå¯ç”¨ç»å…¸è¿‡é‡‡æ ·æ¨¡å¼ï¼‰
    all_less_than_max = all(cnt < config.MAX_SAMPLES_PER_CLASS for cnt in class_counts.values())
    target_samples = None

    # æ­¥éª¤1ï¼šæŒ‰ç±»åˆ«å¤„ç†ï¼ˆæˆªæ–­æˆ–ä¿ç•™åŸå§‹åˆ†å¸ƒï¼‰
    from collections import defaultdict
    from sklearn.utils import resample  # è¡¥å……å¯¼å…¥resample
    np.random.seed(config.RANDOM_STATE)
    class_data = defaultdict(list)
    for feat, label in zip(train_feat_norm, train_label):
        class_data[label].append(feat)

    processed_data = []
    processed_labels = []

    if all_less_than_max:
        # ç»å…¸è¿‡é‡‡æ ·æ¨¡å¼ï¼šç›®æ ‡æ ·æœ¬æ•°è®¾ä¸ºæœ€å¤§ç±»åˆ«æ ·æœ¬æ•°ï¼ˆè®©å°ç±»è¿½å¤§ç±»ï¼‰
        target_samples = max(class_counts.values())
        print(f"   - æ£€æµ‹åˆ°æ‰€æœ‰ç±»åˆ«æ ·æœ¬æ•°å‡å°äºæœ€å¤§é˜ˆå€¼ï¼Œå¯ç”¨ç»å…¸è¿‡é‡‡æ ·æ¨¡å¼")
        print(f"   - ç›®æ ‡ï¼šå°ç±»è¿‡é‡‡æ ·è‡³æœ€å¤§ç±»åˆ«æ ·æœ¬æ•°ï¼ˆ{target_samples}ï¼‰")
        
        # ä¸æˆªæ–­ä»»ä½•ç±»åˆ«ï¼Œç›´æ¥ä¿ç•™åŸå§‹æ ·æœ¬
        for label in class_data:
            samples = np.array(class_data[label])
            processed_data.append(samples)
            processed_labels.append(np.full(len(samples), label))
        
        processed_data = np.concatenate(processed_data, axis=0)
        processed_labels = np.concatenate(processed_labels, axis=0)
    else:
        # åŸé€»è¾‘ï¼šå¤šæ•°ç±»æˆªæ–­è‡³æœ€å¤§æ ·æœ¬æ•°
        print(f"   - å­˜åœ¨ç±»åˆ«æ ·æœ¬æ•°è¶…è¿‡æœ€å¤§é˜ˆå€¼ï¼Œå¯ç”¨æˆªæ–­æ¨¡å¼")
        for label in class_data:
            samples = np.array(class_data[label])
            n_samples = len(samples)
            
            if n_samples > config.MAX_SAMPLES_PER_CLASS:
                # å¤šæ•°ç±»ï¼šéšæœºä¸‹é‡‡æ ·åˆ°max_samples
                selected_idx = np.random.choice(n_samples, config.MAX_SAMPLES_PER_CLASS, replace=False)
                truncated_samples = samples[selected_idx]
            else:
                # å°‘æ•°ç±»ï¼šä¿ç•™å…¨éƒ¨æ ·æœ¬
                truncated_samples = samples
            
            processed_data.append(truncated_samples)
            processed_labels.append(np.full(len(truncated_samples), label))
        
        processed_data = np.concatenate(processed_data, axis=0)
        processed_labels = np.concatenate(processed_labels, axis=0)

    # æ­¥éª¤2ï¼šè¿‡é‡‡æ ·ï¼ˆSMOTEæˆ–Resampleï¼‰
    if config.OVERSAMPLING_STRATEGY == "smote":
        # å¤„ç†å•ç±»åˆ«ç‰¹æ®Šæƒ…å†µ
        unique_labels = np.unique(processed_labels)
        if len(unique_labels) == 1:
            print(f"âš ï¸ ä»…1ä¸ªç±»åˆ«ï¼Œæ— éœ€SMOTEï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            train_feat_final = processed_data
            train_label_final = processed_labels
        else:
            # ç¡®å®šSMOTEç›®æ ‡ï¼šç»å…¸æ¨¡å¼ç”¨æœ€å¤§ç±»åˆ«æ•°ï¼Œå¦åˆ™ç”¨MAX_SAMPLES_PER_CLASS
            smote_target = target_samples if all_less_than_max else config.MAX_SAMPLES_PER_CLASS
            smote = SMOTE(
                sampling_strategy={label: smote_target for label in unique_labels},
                k_neighbors=min(config.N_SMOTE_NEIGHBORS, min(np.bincount(processed_labels)) - 1),
                random_state=config.RANDOM_STATE
            )
            train_feat_final, train_label_final = smote.fit_resample(processed_data, processed_labels)

    elif config.OVERSAMPLING_STRATEGY == "resample":
        # æœ‰æ”¾å›é‡å¤é‡‡æ ·è‡³ç›®æ ‡æ•°
        resampled_data = []
        resampled_labels = []
        for label in np.unique(processed_labels):
            mask = processed_labels == label
            feats_subset = processed_data[mask]
            # ç¡®å®šé‡é‡‡æ ·ç›®æ ‡
            resample_target = target_samples if all_less_than_max else config.MAX_SAMPLES_PER_CLASS
            # é‡å¤é‡‡æ ·
            feats_resampled = resample(
                feats_subset,
                n_samples=resample_target,
                replace=True,
                random_state=config.RANDOM_STATE
            )
            resampled_data.append(feats_resampled)
            resampled_labels.append(np.full(resample_target, label))
        train_feat_final = np.concatenate(resampled_data, axis=0)
        train_label_final = np.concatenate(resampled_labels, axis=0)

    # è¾“å‡ºè¿‡é‡‡æ ·ç»“æœ
    print(f"   - è¿‡é‡‡æ ·åè®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š")
    for cls_id in np.unique(train_label_final):
        cnt = np.sum(train_label_final == cls_id)
        print(f"     * ç±»åˆ«{cls_id}ï¼š{cnt} æ ·æœ¬")
    print(f"   - è¿‡é‡‡æ ·åè®­ç»ƒé›†æ€»æ ·æœ¬æ•°ï¼š{train_feat_final.shape[0]}")

    # è¿”å›é¢„å¤„ç†åçš„æ•°æ®
    return (
        train_feat_final, train_label_final,  # è¿‡é‡‡æ ·åçš„è®­ç»ƒé›†
        val_feat_norm, val_label,             # å½’ä¸€åŒ–åçš„éªŒè¯é›†
        test_feat_norm, test_label,           # å½’ä¸€åŒ–åçš„æµ‹è¯•é›†
        train_mean, train_std                 # å½’ä¸€åŒ–ç»Ÿè®¡é‡ï¼ˆæ¨ç†ç”¨ï¼‰
    )

# ===================== 5. æ•°æ®é›†ä¸DataLoaderå®šä¹‰ï¼ˆæ”¯æŒè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼‰ =====================
class MLPFeatDataset(Dataset):
    def __init__(self, feats, labels):
        self.feats = torch.tensor(feats, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)
        assert len(self.feats) == len(self.labels), "âŒ ç‰¹å¾ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…"
    
    def __len__(self):
        return len(self.feats)
    
    def __getitem__(self, idx):
        return {"feat": self.feats[idx], "label": self.labels[idx]}


def create_dataloaders(train_feat, train_label, val_feat, val_label, test_feat, test_label, config):
    """åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†çš„DataLoader"""
    # è®­ç»ƒé›†ï¼ˆæ‰“ä¹±+ä¸¢å¼ƒä¸å®Œæ•´æ‰¹æ¬¡ï¼‰
    train_dataset = MLPFeatDataset(train_feat, train_label)
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=True,
        drop_last=True,
        pin_memory=True
    )
    
    # éªŒè¯é›†ï¼ˆä¸æ‰“ä¹±ï¼‰
    val_dataset = MLPFeatDataset(val_feat, val_label)
    val_loader = DataLoader(
        val_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        pin_memory=True
    )
    
    # æµ‹è¯•é›†ï¼ˆä¸æ‰“ä¹±ï¼‰
    test_dataset = MLPFeatDataset(test_feat, test_label)
    test_loader = DataLoader(
        test_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        pin_memory=True
    )
    
    print(f"\nğŸš€ DataLoaderåˆ›å»ºå®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†ï¼š{len(train_loader)} æ‰¹ï¼ˆæ¯æ‰¹{config.BATCH_SIZE}æ ·æœ¬ï¼‰")
    print(f"   - éªŒè¯é›†ï¼š{len(val_loader)} æ‰¹")
    print(f"   - æµ‹è¯•é›†ï¼š{len(test_loader)} æ‰¹")
    
    return train_loader, val_loader, test_loader


# ===================== 6. MLPåˆ†ç±»æ¨¡å‹ï¼ˆå›ºå®š768ç»´è¾“å…¥ï¼ŒæŒ‰éœ€æ±‚å®šä¹‰ï¼‰ =====================
class MLPClassifier(nn.Module):
    """è½»é‡çº§MLPåˆ†ç±»å™¨ï¼ˆé€‚é…768ç»´Wav2Vec2ç‰¹å¾ï¼‰"""
    def __init__(self, input_dim=768, num_classes=2, dropout=0.3):
        super().__init__()
        self.classifier = nn.Sequential(
            # ç¬¬ä¸€å±‚ï¼š768 â†’ 512ï¼ˆReLU+Dropoutï¼‰
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            # ç¬¬äºŒå±‚ï¼š512 â†’ 256ï¼ˆReLU+Dropoutï¼‰
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            # è¾“å‡ºå±‚ï¼š256 â†’ ç±»åˆ«æ•°ï¼ˆæ— æ¿€æ´»ï¼ŒCrossEntropyLossè‡ªå¸¦Softmaxï¼‰
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        """x: [batch_size, 768] â†’ logits: [batch_size, num_classes]"""
        return self.classifier(x)


# ===================== 7. è®­ç»ƒä¸è¯„ä¼°å‡½æ•°ï¼ˆæ”¯æŒéªŒè¯é›†ç›‘æ§+æµ‹è¯•é›†è¯¦ç»†è¯„ä¼°ï¼‰ =====================
def train_one_epoch(model, dataloader, criterion, optimizer, scaler, config):
    """è®­ç»ƒä¸€è½®ï¼Œè¿”å›è®­ç»ƒé›†æŒ‡æ ‡"""
    model.train()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    
    for batch in tqdm(dataloader, desc="è®­ç»ƒä¸­"):
        feats = batch["feat"].to(config.DEVICE)
        labels = batch["label"].to(config.DEVICE)
        
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        # æ··åˆç²¾åº¦è®­ç»ƒ
        with autocast():
            logits = model(feats)
            loss = criterion(logits, labels)
        
        # åå‘ä¼ æ’­ä¸ä¼˜åŒ–
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        # ç´¯è®¡ç»“æœ
        total_loss += loss.item() * feats.size(0)
        preds = torch.argmax(logits, dim=1).cpu().numpy()
        all_preds.extend(preds)
        all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—æŒ‡æ ‡
    avg_loss = total_loss / len(dataloader.dataset)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    recall = recall_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    f1 = f1_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    
    return avg_loss, accuracy, precision, recall, f1


def evaluate_model(model, dataloader, criterion, config, is_test=False, class2id=None):
    """è¯„ä¼°æ¨¡å‹ï¼Œè¿”å›æŒ‡æ ‡ï¼›æµ‹è¯•é›†æ—¶è¾“å‡ºè¯¦ç»†ä¿¡æ¯+æ··æ·†çŸ©é˜µ"""
    model.eval()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="è¯„ä¼°ä¸­"):
            feats = batch["feat"].to(config.DEVICE)
            labels = batch["label"].to(config.DEVICE)
            
            with autocast():
                logits = model(feats)
                loss = criterion(logits, labels)
            
            total_loss += loss.item() * feats.size(0)
            preds = torch.argmax(logits, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    avg_loss = total_loss / len(dataloader.dataset)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    recall = recall_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    f1 = f1_score(all_labels, all_preds, average=config.EVAL_METRIC, zero_division=0)
    
    # æµ‹è¯•é›†é¢å¤–å¤„ç†ï¼šè¯¦ç»†æŒ‡æ ‡+æ··æ·†çŸ©é˜µ
    if is_test and class2id is not None:
        id2class = {idx: cls for cls, idx in class2id.items()}
        print(f"\n========== {config.dataset_name} æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°ç»“æœ ==========")
        print(f"1. æ€»ä½“æŒ‡æ ‡ï¼ˆ{config.EVAL_METRIC}å¹³å‡ï¼‰ï¼š")
        print(f"   - æŸå¤±ï¼š{avg_loss:.4f}")
        print(f"   - å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š{accuracy:.4f}")
        print(f"   - ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼š{precision:.4f}")
        print(f"   - å¬å›ç‡ï¼ˆRecallï¼‰ï¼š{recall:.4f}")
        print(f"   - F1åˆ†æ•°ï¼š{f1:.4f}\n")
        
        # è¾“å‡ºå„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡
        class_prec = precision_score(all_labels, all_preds, average=None, zero_division=0)
        class_rec = recall_score(all_labels, all_preds, average=None, zero_division=0)
        class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)
        print(f"2. å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡ï¼š")
        for cls_id in np.unique(all_labels):
            cls_name = id2class[cls_id]
            print(f"   - {cls_name}ï¼ˆID:{cls_id}ï¼‰ï¼š")
            print(f"     ç²¾ç¡®ç‡ï¼š{class_prec[cls_id]:.4f} | å¬å›ç‡ï¼š{class_rec[cls_id]:.4f} | F1ï¼š{class_f1[cls_id]:.4f}")
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆä¿å­˜åˆ°TBç›®å½•ï¼‰
        if config.PLOT_CONFUSION_MATRIX:
            cm = confusion_matrix(all_labels, all_preds)
            # é€‚é…ç±»åˆ«æ•°è°ƒæ•´å›¾å¤§å°
            fig_size = (10 + len(class2id)//3, 8 + len(class2id)//3)
            plt.figure(figsize=fig_size)
            # æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
            sns.heatmap(
                cm,
                annot=True,
                fmt="d",
                cmap="Blues",
                xticklabels=[id2class[idx] for idx in range(len(class2id))],
                yticklabels=[id2class[idx] for idx in range(len(class2id))],
                annot_kws={"fontsize": 8 if len(class2id) > 5 else 10}
            )
            plt.xlabel("Predicted Class", fontsize=12)
            plt.ylabel("True Class", fontsize=12)
            plt.title(f"{config.dataset_name} Test Set Confusion Matrix", fontsize=14, pad=20)
            plt.xticks(rotation=45 if len(class2id) <= 8 else 90, ha="right")
            plt.tight_layout()
            # ä¿å­˜è·¯å¾„ï¼ˆTBç›®å½•ä¸‹ï¼‰
            cm_save_path = os.path.join(config.PLOT_DIR, "test_confusion_matrix.png")
            plt.savefig(cm_save_path, dpi=300, bbox_inches="tight")
            plt.close()
            print(f"\n3. æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³ï¼š{cm_save_path}")
    
    return avg_loss, accuracy, precision, recall, f1


# ===================== 8. ç»“æœè¿½åŠ å‡½æ•°ï¼ˆå†™å…¥å›ºå®šCSVï¼‰ =====================
def append_result_to_csv(config, test_metrics):
    """
    è¿½åŠ å†…å®¹ï¼š
    æ•°æ®é›†å,æ‰¹æ¬¡å¤§å°,å­¦ä¹ ç‡,è¿‡é‡‡æ ·ç­–ç•¥,æ¯ç±»æœ€å¤§æ ·æœ¬æ•°,æµ‹è¯•å‡†ç¡®ç‡,æµ‹è¯•ç²¾ç¡®ç‡,æµ‹è¯•å¬å›ç‡,æµ‹è¯•F1,æµ‹è¯•æŸå¤±
    """
    # è§£ææµ‹è¯•æŒ‡æ ‡
    test_loss, test_acc, test_prec, test_rec, test_f1 = test_metrics
    # æ„é€ ä¸€è¡Œæ•°æ®
    result_row = {
        "dataset_name": config.dataset_name,
        "batch_size": config.BATCH_SIZE,
        "learning_rate": config.LEARNING_RATE,
        "oversampling_strategy": config.OVERSAMPLING_STRATEGY,
        "max_samples_per_class": config.MAX_SAMPLES_PER_CLASS,
        "test_accuracy": round(test_acc, 4),
        "test_precision": round(test_prec, 4),
        "test_recall": round(test_rec, 4),
        "test_f1": round(test_f1, 4),
        "test_loss": round(test_loss, 4),
        "train_epochs": config.EPOCHS
    }
    
    # è½¬æ¢ä¸ºDataFrame
    result_df = pd.DataFrame([result_row])
    # è¿½åŠ åˆ°CSVï¼ˆæ— æ–‡ä»¶åˆ™åˆ›å»ºï¼Œæœ‰åˆ™è¿½åŠ ï¼‰
    if not os.path.exists(config.RESULT_CSV):
        result_df.to_csv(config.RESULT_CSV, index=False, encoding="utf-8")
    else:
        result_df.to_csv(config.RESULT_CSV, index=False, encoding="utf-8", mode="a", header=False)
    
    print(f"\nğŸ“„ ç»“æœå·²è¿½åŠ åˆ°å›ºå®šCSVï¼š{config.RESULT_CSV}")
    print(f"   - è¿½åŠ å†…å®¹ï¼š{result_row}")


# ===================== 9. ä¸»å‡½æ•°ï¼ˆä¸²è”å…¨æµç¨‹ï¼‰ =====================
def main():
    # Step 1ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    # Step 2ï¼šç”ŸæˆåŠ¨æ€é…ç½®
    config = Config(args)
    # Step 3ï¼šåˆ›å»ºå¿…è¦ç›®å½•ï¼ˆTBæ—¥å¿—/æ¨¡å‹/æ··æ·†çŸ©é˜µï¼‰
    os.makedirs(config.TB_LOG_DIR, exist_ok=True)
    print(f"\nğŸ“Œ å®éªŒé…ç½®æ±‡æ€»ï¼š")
    print(f"   - æ•°æ®é›†åï¼š{config.dataset_name}")
    print(f"   - GPUè®¾å¤‡ï¼š{config.DEVICE}")
    print(f"   - è®­ç»ƒè½®æ¬¡ï¼š{config.EPOCHS}")
    print(f"   - TensorBoardæ—¥å¿—ç›®å½•ï¼š{config.TB_LOG_DIR}")
    print(f"   - å›ºå®šç»“æœCSVï¼š{config.RESULT_CSV}")
    
    try:
        # Step 4ï¼šåŠ è½½ç‰¹å¾ä¸æ ‡ç­¾
        all_feats, all_labels, class2id = load_dataset_features(config)
        num_classes = len(class2id)
        
        # Step 5ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆåˆ’åˆ†+å½’ä¸€åŒ–+è¿‡é‡‡æ ·ï¼‰
        (train_feat, train_label, 
         val_feat, val_label, 
         test_feat, test_label, 
         train_mean, train_std) = preprocess_data(all_feats, all_labels, config)
        
        # Step 6ï¼šåˆ›å»ºDataLoader
        train_loader, val_loader, test_loader = create_dataloaders(
            train_feat, train_label, val_feat, val_label, test_feat, test_label, config
        )
        
        # Step 7ï¼šåˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
        model = MLPClassifier(
            input_dim=768,
            num_classes=num_classes,
            dropout=config.DROPOUT
        ).to(config.DEVICE)
        print(f"\nğŸš€ MLPæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼š")
        print(f"   - è¾“å…¥ç»´åº¦ï¼š768")
        print(f"   - è¾“å‡ºç»´åº¦ï¼š{num_classes}ï¼ˆç±»åˆ«æ•°ï¼‰")
        print(f"   - ç½‘ç»œç»“æ„ï¼š768â†’512â†’256â†’{num_classes}ï¼ˆReLU+Dropout={config.DROPOUT}ï¼‰")
        
        # æŸå¤±å‡½æ•°ï¼ˆå¤šåˆ†ç±»äº¤å‰ç†µï¼‰
        criterion = nn.CrossEntropyLoss()
        # ä¼˜åŒ–å™¨ï¼ˆAdamWå¸¦æƒé‡è¡°å‡ï¼‰
        optimizer = optim.AdamW(
            model.parameters(),
            lr=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY
        )
        # æ··åˆç²¾åº¦è®­ç»ƒå™¨
        scaler = GradScaler()
        
        # Step 8ï¼šåˆå§‹åŒ–TensorBoardï¼ˆè®°å½•è®­ç»ƒ/éªŒè¯/æµ‹è¯•æŒ‡æ ‡ï¼‰
        tb_writer = SummaryWriter(log_dir=config.TB_LOG_DIR)
        # è·Ÿè¸ªæœ€ä¼˜æ¨¡å‹ï¼ˆåŸºäºéªŒè¯é›†F1ï¼‰
        best_val_f1 = 0.0
        best_model_path = os.path.join(config.SAVE_MODEL_DIR, "best_model.pth")
        # è®­ç»ƒæ—¥å¿—ï¼ˆç”¨äºç¦»çº¿åˆ†æï¼‰
        train_logs = []
        
        # Step 9ï¼šè®­ç»ƒå¾ªç¯ï¼ˆéªŒè¯é›†ç›‘æ§æœ€ä¼˜æ¨¡å‹ï¼‰
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼ˆå…±{config.EPOCHS}è½®ï¼‰")
        for epoch in range(1, config.EPOCHS + 1):
            print(f"\n===== Epoch {epoch}/{config.EPOCHS} =====")
            
            # è®­ç»ƒä¸€è½®
            train_loss, train_acc, train_prec, train_rec, train_f1 = train_one_epoch(
                model, train_loader, criterion, optimizer, scaler, config
            )
            
            # éªŒè¯é›†è¯„ä¼°
            val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate_model(
                model, val_loader, criterion, config, is_test=False
            )
            
            # æ‰“å°æœ¬è½®æŒ‡æ ‡
            print(f"ğŸ“Š è®­ç»ƒé›†ï¼š")
            print(f"   æŸå¤±ï¼š{train_loss:.4f} | å‡†ç¡®ç‡ï¼š{train_acc:.4f} | F1ï¼š{train_f1:.4f}")
            print(f"ğŸ“Š éªŒè¯é›†ï¼š")
            print(f"   æŸå¤±ï¼š{val_loss:.4f} | å‡†ç¡®ç‡ï¼š{val_acc:.4f} | F1ï¼š{val_f1:.4f}")
            
            # è®°å½•åˆ°TensorBoard
            # è®­ç»ƒé›†æŒ‡æ ‡
            tb_writer.add_scalar(f"{config.dataset_name}/Loss/Train", train_loss, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/Accuracy/Train", train_acc, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/Precision/Train", train_prec, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/Recall/Train", train_rec, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/F1/Train", train_f1, epoch)
            # éªŒè¯é›†æŒ‡æ ‡
            tb_writer.add_scalar(f"{config.dataset_name}/Loss/Val", val_loss, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/Accuracy/Val", val_acc, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/Precision/Val", val_prec, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/Recall/Val", val_rec, epoch)
            tb_writer.add_scalar(f"{config.dataset_name}/F1/Val", val_f1, epoch)
            
            # ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆåŸºäºéªŒè¯é›†F1ï¼‰
            if val_f1 > best_val_f1:
                best_val_f1 = val_f1
                torch.save({
                    "model_state_dict": model.state_dict(),
                    "class2id": class2id,
                    "train_mean": train_mean,
                    "train_std": train_std,
                    "dataset_name": config.dataset_name
                }, best_model_path)
                print(f"âœ… ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆéªŒè¯é›†F1ï¼š{best_val_f1:.4f}ï¼‰è‡³ï¼š{best_model_path}")
            
            # è®°å½•è®­ç»ƒæ—¥å¿—
            train_logs.append({
                "epoch": epoch,
                "train_loss": train_loss, "train_acc": train_acc, "train_f1": train_f1,
                "val_loss": val_loss, "val_acc": val_acc, "val_f1": val_f1
            })
        
        # Step 10ï¼šåŠ è½½æœ€ä¼˜æ¨¡å‹è¿›è¡Œæµ‹è¯•é›†è¯„ä¼°
        print(f"\n========== åŠ è½½æœ€ä¼˜æ¨¡å‹è¯„ä¼°æµ‹è¯•é›† ==========")
        checkpoint = torch.load(best_model_path)
        best_model = MLPClassifier(
            input_dim=768,
            num_classes=num_classes,
            dropout=config.DROPOUT
        ).to(config.DEVICE)
        best_model.load_state_dict(checkpoint["model_state_dict"])
        
        # æµ‹è¯•é›†è¯„ä¼°ï¼ˆè¾“å‡ºè¯¦ç»†ä¿¡æ¯+æ··æ·†çŸ©é˜µï¼‰
        test_metrics = evaluate_model(
            best_model, test_loader, criterion, config, 
            is_test=True, class2id=class2id
        )
        
        # Step 11ï¼šå°†æµ‹è¯•ç»“æœè¿½åŠ åˆ°å›ºå®šCSV
        append_result_to_csv(config, test_metrics)
        
        # Step 12ï¼šè®­ç»ƒå®Œæˆ
        print(f"\nğŸ‰ {config.dataset_name} æ•°æ®é›†è®­ç»ƒå®Œæˆï¼")
        print(f"   - æœ€ä¼˜æ¨¡å‹è·¯å¾„ï¼š{best_model_path}")
        print(f"   - TensorBoardå¯åŠ¨å‘½ä»¤ï¼štensorboard --logdir={config.TB_LOG_DIR}")
        print(f"   - ç»“æœCSVè·¯å¾„ï¼š{config.RESULT_CSV}")
    
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
        raise  # æŠ›å‡ºå¼‚å¸¸ä¾¿äºè°ƒè¯•


if __name__ == "__main__":
    main()